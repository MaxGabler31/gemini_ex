Prompt: Summarize the business model from the following text. Answer with a continuous text and with fivehundredtwelve tokens at max. Set your focus on sources of revenue , the intended customer base , products , distribution channels  and details of financing. Use only information from the following the text:

 Item 1.  Business
 Overview
 MoSys, Inc., together with its subsidiaries (“MoSys,” the “Company,” “we,” “our” or “us”), is a fabless semiconductor company focused on the development and sale of integrated circuits, or ICs, for the high-speed cloud networking, communications, security appliance, video, monitor and test, data center and computing markets. Our solutions deliver time-to-market, performance, power, area and economic benefits for system original equipment manufacturers, or OEMs. Our primary product line is marketed under the Bandwidth Engine and Programmable Search Engine names and marks, and these IC products integrate our proprietary, 1T-SRAM® high-density embedded memory and a highly-efficient serial interface protocol resulting in a monolithic memory IC solution optimized for memory bandwidth and transaction access performance.   Further performance benefits can be achieved to offload statistical, search or other custom functions using our optional integrated logic and processor elements.  As data rates and the amount of high-speed processing increase, critical memory access bottlenecks occur. Our Bandwidth Engine, or BE, and Programmable Search Engine, or PSE, ICs drastically increase memory accesses per second, removing these bottlenecks. In addition, the serial interface and high-memory capacity reduce the board footprint, number of pins and complexity, while using less power. 
 In April 2017, we implemented restructuring initiatives to effect a reduction in our workforce and associated operating expenses, net loss and cash burn. Under these initiatives, we significantly reduced our headcount, closed international sales offices and relocated and downsized our corporate headquarters. We are primarily focusing our resources on producing and selling our existing products, and have substantially curtailed new product development. Despite the reduction in new product development, we believe our current product portfolio and roadmap position us for future growth and profitability.  We will continue to seek opportunities to sell existing products, license our technology and obtain third-party funding for new product development efforts. Our future success and ability to achieve and maintain profitability are dependent on the marketing and sales of our IC products into cloud networking, communications, security appliances, monitoring and test, data center, video, and other markets requiring high-bandwidth memory access.
 Industry Background
 The amount of data and the number of users and devices is growing exponentially, driven primarily by commercial and consumer cloud applications, video services, high speed mobile networks, Internet of Things, or IoT, and many other cloud applications. In order to meet these demands, the new cloud infrastructure; including the backbone, edge, access network and data centers must scale in both speed and intelligence to handle real-time security, bandwidth allocation, and service-level expectations. In addition, workloads or applications delivered at a massive scale from the cloud require flexible, efficient data and computing transmission to optimize resources to enable these applications and lower the overall cost, size and power of the data center. These increased demands strain 

 
  3

 
communication between onboard IC devices, limiting the data throughput in network switches and routers and the network backbone.
 To meet these demands, carrier and enterprise networks are merging with the cloud and are undergoing significant changes and, most significantly, are migrating to packet-based Ethernet networks that enable higher throughput, lower cost and uniform technology across access, core and metro network infrastructure. These networks are now being designed to deliver voice, video and high-speed Internet services on one converged, efficient and flexible network. These trends require networking systems, especially the high-speed switches and routers that primarily comprise these networks, to comply with evolving market requirements and be capable of providing new services and better quality of service while supporting new protocols and standards. To support these trends, traditional OEM network and telecommunications equipment manufacturers, such as Alcatel-Lucent (a subsidiary of Nokia Corporation), Cisco Systems, Inc., Tel. LM Ericsson, Fujitsu Ltd., Hitachi Ltd., Huawei Technologies, Juniper Networks, Inc., Nokia Corporation, and ZTE Corporation, as well as a new set of white-box solutions from new vendors and cloud-service providers, must offer higher levels of packet forwarding rates, bandwidth density and be optimized to enable higher-density, lower power data path connectivity in the next generations of their networking systems.
 Networking communications, security, video and computing systems throughout the cloud network must operate at higher speed and performance levels, and so require new generations of packet processors and improved memory subsystems to enable system performance. These systems and their component line cards generally need to support aggregate rates of 100 gigabits per second, or Gbps, and above to meet the continued growth in network traffic. Cloud services have accelerated this transition with applications such as security. Data centers and access equipment that were previously aggregating slower traffic at rates of 1Gbps to 10Gbps, and 40Gbps, now are being designed to aggregate traffic at 100 Gbps, or more. The transition to 100 Gbps networks is underway, and the increase in data rates for these networks is expected to continue to grow rapidly over the coming years. 
 Several types of semiconductors are included on each line card, including one or more processors and multiple memory chips. These processors are complex ICs or IC chipsets that perform high-speed data or packet processing for functions, such as traffic routing, shaping, metering, billing, statistics, detection, steering, security, video processing, monitoring and workload acceleration. The line cards use various types of memory ICs to facilitate temporary packet storage and assist in the analysis and tracking of information embedded within the data flowing through the processors. After a packet enters the line card, a packet or data processor helps separate the packet into smaller pieces for rapid analysis. In a typical packet-based network for example, the data is broken up into the packet header, which contains vital information on packet destination and type, such as the Internet protocol address, and the payload, which contains the data being sent. Generally, the line card operations must occur at full data rates and typically require accessing memory ICs many times. Simultaneously, the packet’s payload, which may be substantially larger than the packet header, is also stored in memory ICs until processing is complete and the packet can re-combine and be sent to its next system destination. Within the line card, communication between the packet processor and memory ICs occurs through an interface consisting of combinations of physical pins on each type of chip. These pins are grouped together in a parallel or a serial architecture to form a pathway, called a bus, through which information is transferred from one IC to the next.
 Today, the majority of physical buses that connect networking equipment and components use a parallel architecture to communicate between processors and memory ICs, which means information can travel only in one direction and in one instance at a time. As processing speeds increase, the number of pins required and the speed of the bus in a parallel architecture become a limitation on system performance and capability. In contrast, the number of connections is reduced substantially across fewer, higher-rate pins in a serial architecture, and data is transferred simultaneously in both directions. Data transfer rates are limited by the data access rates of the various ICs included on the line card, thus leading to bottlenecks when these ICs perform inadequately. In order to remove these bottlenecks and meet next-generation bandwidth requirements, the line card ICs need to support higher access rates enabled by internal memory or high-speed serial bus architectures and these more advanced interface protocols.
 Most networking and communication systems sold and in operation today include line cards that process data at speeds ranging from 10 Gbps, to 100 Gbps, and support many aggregated slower ports. To accommodate the substantial and growing increase in demand for networking communications and applications, networking systems manufacturers are developing and bringing to market next-generation systems that run at aggregate speeds of 100 Gbps to 400 Gbps or more with developments underway to scale to thousands of Gbps, or terabits, per second. However, although processor performance in applications such as computing and networking has continued to double nearly every 18 months, or even 

 
  4

 
sooner, the performance of memory technology has generally been able to double only once every 10 years. Existing memory IC solutions based on parallel interface architecture easily support speeds up to 40 Gbps, but are not optimal for meeting speeds of 100 Gbps and beyond due to system-level limitations for pin counts, power and performance. These networking and communications systems are generally comprised of a chassis populated by four to 16 line cards. Often, these systems are shipped to customers with only a portion of the line card slots populated, and the customer will add additional line cards subsequently to increase system performance, capacity and features.
 Each line card requires a significant amount of memory to support its processing capabilities. Traditional external memory IC solutions currently used on line cards include both dynamic random access memory, or DRAM, and static random access memory, or SRAM. Line cards in networking systems use both specialized, high-performance DRAM ICs, such as reduced-latency DRAM, or RLDRAM, low-latency DRAM, or LLDRAM, and commodity DRAM, such as double data rate, or DDR ICs.  The latest DDR memory called high-bandwidth memory, or HBM, provides high bandwidth, but has fundamentally slow access time.  For very high access, networking systems use higher-performance SRAM ICs such as quad data rate, or QDR SRAM. These memories are very fast, but are much smaller, more costly and burn more power than traditional DRAM. Substantially all of these traditional memory IC solutions use parallel interfaces, which are slower than serial interfaces, so we believe they will be increasingly challenged to meet the performance, pin count, area and power requirements as networking systems expand beyond 100 Gbps. The result is a gap between processor and memory performance. To meet the higher performance requirements being demanded by the industry, while using current components and architectural approaches, system designers must add more discrete memory ICs to the line cards and/or add more embedded memory on the packet processor. This results in higher cost and power consumption, the use of more space on the line cards and additional communication interference between the ICs, which in turn results in additional bandwidth limitation problems. We believe our Bandwidth Engine family of products is well suited to address these challenges and replace these traditional memory solutions.
 We have developed our ICs to synergistically address the need for high-speed data access and throughput currently confronting system designers. We expect our IC products to meet the increasing demands placed on conventional memory technology used on the line cards in high-speed systems. We believe that our products and technology are well positioned as replacements for existing IC solutions in order to meet the needs of a growing number of data processing applications with aggregate rates greater than 100 Gbps that require high bandwidth and high access rate to memory.
 Our Approach
 We have leveraged our proprietary intellectual property, or IP, to design our IC products to help networking OEMs address the growing bottlenecks in system performance. We have incorporated critical features into our product families to accomplish this objective.
 On-Chip Acceleration
 One significant performance bottleneck in any network line card is the need to transfer data between discrete ICs. Many of these data-transfer operations are iterative in nature, requiring subsequent, back-to-back accesses of the memory IC by the processor IC. Our Bandwidth Engine ICs include an arithmetic logic unit, or ALU, which enables the performance of mathematical operations on data. Moving certain processing functions from the processor IC to the Bandwidth Engine IC through the use of this embedded ALU, reduces the number of processing transactions and frees the processor IC to perform other important networking or micro-processing functions.
 The PSE takes this concept one step further by incorporating integrated search-optimized processors.  The processors can be programmed by the user to offload and accelerate standard and/or customized functions from the main processor thereby reducing memory transactions and data path complexity to provide improved performance and lower system latency.
 High-Performance Interface
 High-speed, efficient interfaces are critical building blocks to meet high data transfer rate requirements for communication between ICs on network line cards. We believe that current networking system requirements necessitate an industry transition from parallel to serial interface. As a result, semiconductor companies are increasingly turning to serial interface architectures to achieve needed system performance. For example, high-performance ICs that are sold 

 
  5

 
into wide markets, such as field programmable gate arrays, or FPGAs, and network processing units, NPUs, are using serial interfaces to ensure they can compete with custom designed application specific ICs, or ASICs, by matching their performance. Using serial interfaces, IC developers also are able to reduce pin count (the wired electrical pins that connect an IC to the network line card on which it is mounted) on the IC. With reducing geometries, the size of most high-performance ICs is dictated by the number of pins required, rather than the amount of logic and memory embedded in the chip. As a result, using serial interface facilitates cost reduction and reduced system power consumption, while improving the performance of both the IC itself and the overall system. While serial interfaces provide significantly enhanced performance over parallel interfaces, SerDes interfaces traditionally have had higher power consumption, which is a challenge for IC designers. Our SerDes interfaces, however, are optimized to meet our customers’ signal integrity, low- power consumption and latency requirements.
 We make our interface technologies compliant with industry standards so that they can interoperate with interfaces on existing ICs. In addition, we make them programmable to support multiple data rates, which allows for greater flexibility for the system designer, while lowering their development and validation costs. Interoperability reduces development time, thereby reducing the overall time to market of our customers’ systems.
 GigaChip Interface Protocol
 In addition to the physical characteristics of the serial interface, the protocol used to transmit data is also an important element that impacts speed and performance. To address this and complement our Bandwidth Engine devices, we have developed the GigaChip Interface®, or GCI, which is an open-interface transport protocol optimized for efficient chip-to-chip communications. The GCI electrical interface is compatible with the current industry standard (Common Electrical Interface, release #11, or CEI-11G-SR and XFI) to simplify electrical interoperability between devices. GCI can enable highly efficient serial chip-to-chip communications, and its transport efficiency averages 90% for the data transfers it handles. GCI is included in our ICs and is offered to customers and prospective partners on terms intended to encourage widespread adoption.
 High-Performance and High-Density Memory Architecture
 The high-density of our proprietary 1T-SRAM technologies stems from the use of a single-transistor, or 1T, which is similar to DRAM, with a storage cell for each bit of information. Embedded memory utilizing our 1T-SRAM technologies is typically two to three times denser than the six-transistor storage cells used by traditional SRAM, or 6T-SRAM. Embedded memory utilizing our 1T-SRAM technologies typically provides speeds essentially equal to or greater than the speeds of traditional SRAM and DRAM, particularly for larger memory sizes. Our 1T-SRAM memory designs can sustain random access cycle times of less than three nanoseconds, significantly faster than DRAM technology. Embedded memory utilizing our 1T-SRAM technologies can consume as little as one-half the active power and generate less heat than traditional SRAM when operating at the same speed. The 1T-SRAM allows us to integrate more high-performance memory using less expensive processing technology, reduces system level heat dissipation and enables reliable operation using lower-cost packaging.
 Our Strategy
 Our primary business objective is to be a profitable IP-rich fabless semiconductor company offering ICs that deliver unparalleled memory bandwidth and access rate performance for high-performance data processing in cloud networking, security appliances, video, test and monitoring, and data center systems. The key components of our strategic plan include the following strategies: Target Large and Growing Markets
 Our initial strategy is to target the multi-billion dollar networking telecommunications, security appliance and data center OEM equipment markets, and we have developed products to support the growth in 100 Gbps and higher networking speeds. We are currently supporting numerous customers, with whom we have achieved design wins. We continue to actively pursue additional design wins for the use of our ICs in our target markets. We believe our design wins represent the potential for significant future revenue growth. With limited history to date, however, we cannot estimate how much revenue each design win is likely to generate, or how much revenue all of these (and future design wins) are likely to generate. There is no assurance that these customer designs will be shipped in large volume by our customers to their customers, however.    
 
  6

 

 Expand Adoption of the GigaChip Interface Protocol
 We have provided our GCI interface protocol as an open industry standard that may be designed into other ICs in the system, as we believe this will further enable serial communication on network line cards and encourage adoption of our Bandwidth Engine IC products. A number of IC providers and partners have publicly announced their support of GCI and Bandwidth Engine, including the largest FPGA providers, Altera Corporation (a subsidiary of Intel Corporation), Xilinx, Inc., and EZchip Semiconductor Ltd. (a subsidiary of Mellanox Technologies Ltd.), with whom we work closely to support common customers. In addition, multiple networking systems companies, including actual and prospective customers, have adopted GCI.
 Build Long-Term Relationships with FPGA Vendors and Suppliers of Data Processing Solutions
 We believe that having long-term relationships with FPGA providers is critical to our success, as such relationships enable us to reduce our time-to-market, provide us with a competitive advantage and expand our target markets. A key consideration of network system designers is to demonstrate interoperability between our IC products and the data processing utilized in their systems. To obtain design wins, we must demonstrate this interoperability, and also show that our IC works optimally with the packet processor to achieve the performance requirements. In addition, our current strategy requires packet processor suppliers to adopt our GCI interface. To that end, we have been working closely with FPGA and application specific standard product providers, to enable interoperability between our Bandwidth Engine IC products and their high-performance products. To facilitate the acceptance of our Bandwidth Engine ICs, we have made available development and characterization kits for system designers to evaluate and develop code for next-generation networking systems. Our characterization kits are fully-functional hardware platforms that allow FPGA and ASIC providers, and their customers, to demonstrate interoperability of the Bandwidth Engine IC with the ASIC or FPGA the designers use within their networking systems. 
 Our Bandwidth Engine Products
 The Bandwidth Engine is a memory-dominated IC that has been designed to be a high-performance companion IC to packet processors. While the Bandwidth Engine primarily functions as a memory device with a high-performance and high-efficiency interface, it also can accelerate certain processing operations by serving as a co-processor element. Our Bandwidth Engine ICs combine: (1) our proprietary high-density, high-speed, low latency embedded memory, (2) our high-speed serial interface technology, or SerDes, (3) an open-standard interface protocol and (4) intelligent access technology. We believe an IC combining our 1T-SRAM memory and serial interface with logic and other intelligence functions provides a system-level solution and significantly improves overall system performance at lower cost, size and power consumption. Our Bandwidth Engine ICs can provide up to and over 4.5 billion memory accesses per second, which is more than twice the performance of current memory-based solutions. They also can enable system designers to significantly narrow the gap between processor and memory IC performance. Customers that design Bandwidth Engine ICs onto the line cards in their networking systems will re-architect their systems at the line-card level and use our product to replace traditional memory solutions. When compared with existing commercially available solutions, our Bandwidth Engine ICs may:
· | provide up to four times the performance;
--+------------------------------------------


· | reduce power by approximately 50%;
--+-----------------------------------


· | reduce cost by greater than 50%; and
--+-------------------------------------


· | result in a dramatic reduction in IC pin counts on the line card.
--+------------------------------------------------------------------

  Our first-generation Bandwidth Engine IC products contain 576 megabytes, or MB, of memory and use a serial interface with up to 16 lanes operating at up to 10.3 Gbps per lane. We announced the end-of-life of these products and expect to complete fulfillment of last-time customer orders by December 31, 2018.
 Our second-generation Bandwidth Engine IC products contain 576 MB of memory and use a SerDes interface with up to 16 lanes operating at up to 15 Gbps per lane. In addition to a speed improvement of up to 50% over our first-generation products, the architecture has enabled multiple family-member parts with added specialized features. We 

 
  7

 
have been shipping our Bandwidth Engine 2 IC products since 2013 and expect these products to be our primary revenue source for the foreseeable future.
 Our third-generation Bandwidth Engine IC products contain 1152 MB of memory and use a SerDes interface with up to 16 lanes operating at up to 30 Gbps per lane. Bandwidth Engine 3 targets support for packet-processing applications with up to five billion memory single word accesses per second, as well as burst mode to enable full duplex buffering up to 400 Gbps for ingress, egress and oversubscription applications. The devices provide benefits of size, power, pin count and cost savings to our customers. We do not anticipate significant revenues from these products until 2019 or later.
 Programmable Search Engine (PSE)
 We brought our PSE IC products to market in 2016 to further leverage our proven serial interface technology and high-density integrated memory with the processor engine architecture to enable high-speed customizable search, security, and data analysis functions for networking, security, and data center applications. Our PSE architecture features 32 search-optimized processor engines, data flow schedulers, and over a terabit of internal access bandwidth. The device leverages our GCI technology and high-density integrated memory (1152 Mb of 1T-SRAM embedded memory). 
 IP Licensing and Distribution
 Historically, we have offered our memory and interface technologies on a worldwide basis to semiconductor companies, electronic product manufacturers, foundries, intellectual property companies and design companies through product development, technology licensing and joint marketing relationships. We licensed our IP technology to semiconductor companies who incorporated our technology into ICs that they sold to their customers. As a result of the change in our corporate strategy, since early 2012, our IP licensing activities have been limited, and we expect this to continue. Royalty and other revenue generated from our existing IP agreements represented 45% of our total revenue in 2015 and 24% in 2016. However, during 2017, 11% of our total revenues were generated from royalties related to our existing licensing arrangements, as we continue to collect royalties from 1T-SRAM licensees. Licensing and royalty revenues have been declining since 2010, and we expect continued decline of royalty revenues in 2018.
 Research and Development
 Our ability to compete in the future depends on successfully improving our technology to meet the market’s increasing demand for higher performance and lower cost requirements. Development of our IC products requires specialized chip design and product engineers, as well as significant fabrication and testing costs, including mask costs, as we bring these products to market.  During 2017, we substantially reduced our headcount, and have limited internal resources available for new IC product development, which will result in fewer product improvements and new developments. In the near term, our planned product roadmap will include software-based capabilities and features that leverage our existing base of IC products. Sales and Marketing
 We believe that systems OEMs typically prefer to extend the use of traditional memory solutions and their parallel interfaces, despite performance and costs challenges, and are reluctant to change their technology platforms and adopt new designs and technologies, such as serial interfaces, which are an integral part of our product solutions. Therefore, our principal selling and marketing activities to date have been focused on persuading these OEMs and key component specialists that our solutions provide critical performance advantages, as well as on securing design wins with them.
 In addition to our direct sales personnel, we sell through sales representatives and distributors in the United States and Asia. We also have applications engineers who support our customer engagements and engage with the customers’ system architects and designers to propose and implement our IC and IP solutions, such as the GCI Interface, to address their systems challenges.
 In the markets we serve, the time from initial customer engagement to design win to production volume shipments can range from 18 to 36 months. Networking, communications and security appliance systems can have a product life from a few years to over 10 years once a product like ours has been designed into the system.

 
  8

 

 Our revenue has been highly concentrated, with a few customers accounting for a significant percentage of our total revenue. For the year ended December 31, 2017, Flextronics, which primarily purchases on behalf of Palo Alto Networks, Inc. and Nokia, formerly Alcatel-Lucent, Clavis Company, formerly Kogent, our Japanese IC distributor and Nokia, represented 46%, 17% and 11% of total revenue, respectively. For the year ended December 31, 2016, Alcatel-Lucent, Clavis Company and Taiwan Semiconductor Manufacturing Co., Ltd., or TSMC, represented 47%, 21% and 13% of total revenue, respectively. For the year ended December 31, 2015, Alcatel-Lucent, TSMC and Clavis Company represented 34%, 31% and 12% of total revenue, respectively.
 Intellectual Property
 We regard our patents, copyrights, trademarks, trade secrets and similar intellectual property as critical to our success, and rely on a combination of patent, trademark, copyright, and trade secret laws to protect our proprietary rights.
 As of December 31, 2017, we held 69 U.S. and 42 foreign patents on various aspects of our technology, with expiration dates ranging from 2018 to 2035. We also held 11 pending patent applications in the U.S. and abroad. There can be no assurance that others will not independently develop or patent similar or competing technology or design around any patents that may be issued to us, or that we will be able to successfully enforce our patents against infringement by others.
 In December 2011, we sold 43 United States and 30 related foreign memory technology patents for $35 million in cash pursuant to a patent purchase agreement. Under the agreement, we retained a license to all of the sold patents that is unlimited with respect to our development, manufacturing and distribution of our Bandwidth Engine IC product line and any other proprietary products that we develop, as long as they are not DRAM ICs. We also retained the rights necessary to renew existing 1T-SRAM licenses and to grant licenses similar in scope to identified foundries. We also retained rights to grant licenses for our second source purposes, to enable certain kinds of technology development and, to a limited extent, for certain ASIC products that incorporate one of our technology macros. However, the patent purchase agreement limits our rights to grant licenses under the sold patents outside the scope of our retained license, and, in particular, limits the number of future licenses of 1T-SRAM memory technology that we can grant to developers of systems-on-chips, which used to be the principal focus of our 1T-SRAM licensing activities.
 The semiconductor industry is characterized by frequent litigation regarding patent and other intellectual property rights. Our licensees or we might, from time to time, receive notice of claims that we have infringed patents or other intellectual property rights owned by others. Our successful protection of our patents and other intellectual property rights and our ability to make, use, import, offer to sell, and sell products free from the intellectual property rights of others are subject to a number of factors, particularly those described in Part I, Item 1A, “Risk Factors.”
 Competition
 The markets for our products are highly competitive. We believe that the principal competitive factors are:

· | processing speed and performance;
--+----------------------------------


· | density and cost;
--+------------------


· | power consumption;
--+-------------------


· | reliability;
--+-------------


· | interface requirements;
--+------------------------


· | ease with which technology can be customized for and incorporated into customers’ products; and
--+------------------------------------------------------------------------------------------------


· | level of technical support provided.
--+-------------------------------------

  We believe that our products compete favorably with respect to each of these criteria. Our proprietary 1T-SRAM embedded memory and high-speed serial interface IP can provide our Bandwidth Engine ICs with a competitive advantage over alternative devices. Alternative solutions are either DRAM or SRAM-based and can support either the memory size or speed requirements of high-performance networking systems, but generally not both. DRAM solutions provide a significant amount of memory at competitive cost, but DRAM solutions do not have the required fast access and cycle times to enable high-performance. The DRAM solutions currently used in networking systems include RLDRAM from Micron Technology, Inc., or Micron, and Integrated Silicon Solutions, Inc., LLDRAM from Renesas, DDR from Samsung Electronics Co., Ltd., Micron and others, and HBM, which is stacked memory from Samsung 

 
  9

 
Electronics Co. and SK Hynix. SRAM solutions can meet high-speed performance requirements, but often lack adequate memory size. The SRAM solutions currently used in networking systems primarily include QDR or similar SRAM products from Cypress Semiconductor Corporation and GSI Technology, Inc. Most of the currently available SRAM and DRAM solutions use a parallel, rather than a serial interface. To offset these drawbacks, system designers generally must use more discrete memory ICs, resulting in higher power consumption and greater utilization of space on the line card.
 Our competitors include established semiconductor companies with significantly longer operating histories, greater name recognition and reputation, large customer bases, dedicated manufacturing facilities and greater financial, technical, sales and marketing resources. This may allow them to respond more quickly than us to new or emerging technologies or changes in customer requirements. Generally, customers prefer suppliers with greater financial resources than we have currently. Many of our competitors also have significant influence in the semiconductor industry. They may be able to introduce new technologies or devote greater resources to the development, marketing and sales of their products than we can. Furthermore, in the event of a manufacturing capacity shortage, these competitors may be able to manufacture products when we are unable to do so.
 Our Bandwidth Engine ICs compete with embedded memory solutions, stand-alone memory ICs, including both DRAM and SRAM ICs, and ASICs designed by customers in-house to meet their system requirements. Our prospective customers may be unwilling to adopt and design-in our ICs due to the uncertainties and risks surrounding designing a new IC into their systems and relying on a supplier that has limited history of manufacturing such ICs and limited financial resources. In addition, Bandwidth Engine ICs require the customer and its other IC suppliers to implement our chip-to-chip communication protocol, the GCI interface. These parties may be unwilling to do this if they believe it could adversely impact their own future product developments or competitive advantages, or, if they believe it might complicate their development process or increase the cost of their products. To remain competitive, we believe we must provide unparalleled memory IC solutions with the highest bandwidth capability for our target markets, which solutions are engineered and built for high-reliability carrier and enterprise applications.
 Manufacturing
 We depend on third-party vendors to manufacture, package, assemble and test our IC products, as we do not own or operate a semiconductor fabrication, packaging or production testing facility for boards and system assembly. By outsourcing manufacturing, we can avoid the high cost associated with owning and operating our own facilities, allowing us to focus our efforts on the design and marketing of our products.
 We perform an ongoing review of product manufacturing and testing processes. Our IC products are subjected to extensive testing to assess whether their performance meets design specifications. Our test vendors provide us with immediate test data and the ability to generate characterization reports that are made available to our customers. We have achieved ISO 9001:2008 certification, and all of our manufacturing vendors have also achieved ISO 9001 certification.
 Employees
 As of December 31, 2017, we had 24 employees all of whom are located in the United States, consisting of 14 in research and development and manufacturing operations and 10 in sales, general and administrative functions.  Available Information
 We were founded in 1991 and reincorporated in Delaware in September 2000. Our website address is www.mosys.com. The information in our website is not incorporated by reference into this report. Through a link on the Investor section of our website, we make available our annual reports on Form 10-K, quarterly reports on Form 10-Q, current reports on Form 8-K, and any amendments to those reports filed or furnished pursuant to Section 13(a) or 15(d) of the Securities Exchange Act of 1934, as soon as reasonably practicable after they are filed with, or furnished to, the Securities and Exchange Commission, or SEC. You can also read and obtain copies of any materials we file with the SEC at the SEC’s Public Reference Room at 450 Fifth Street, NW, Washington, DC 20549. You can obtain additional information about the operation of the Public Reference Room by calling the SEC at 1.800.SEC.0330. In addition, the SEC maintains a website (www.sec.gov) that contains reports, proxy and information statements, and other information regarding issuers that file electronically with the SEC, including us.

 
  10

 


