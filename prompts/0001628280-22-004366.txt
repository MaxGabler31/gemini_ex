Prompt: Summarize the business model from the following text. Answer with a continuous text and with fivehundredtwelve tokens at max. Set your focus on sources of revenue , the intended customer base , products , distribution channels  and details of financing. Use only information from the following the text:

ITEM 1. BUSINESS.
Overview 
Luminar is a global automotive technology company ushering in a new era of vehicle safety and autonomy. We are enabling solutions for series production passenger cars and commercial trucks as well as other targeted markets. 
Founded in 2012 by President and Chief Executive Officer Austin Russell, Luminar built a new type of lidar from the chip-level up, with technological breakthroughs across all core components. As a result, we have created what we believe is the lidar sensor that meets the demanding performance, safety, and cost requirements for Level 3 through Level 5 (see Market Outlook for definition of levels of automation) autonomous vehicles in production, bypassing the traditional limitations of legacy lidar technology, while also enabling Level 0 through Level 3 (Advanced Driving Assistance Systems (“ADAS”) and/or Luminar Proactive SafetyTM) with our Proactive SafetyTM solution. Integrating this advanced hardware with our custom developed software stack enables a turn-key autonomous solution to accelerate widespread adoption across automakers at series production scale. 
Our lidar hardware and software products help set the standard for safety in the industry, and are designed to enable accurate and reliable detections of some of the most challenging “edge cases” autonomous vehicles can encounter on a regular basis. This is achieved by advancing existing lidar range and resolution to new levels, ensuring hard-to-see objects like a tire on the road ahead or a child that runs into the street are not missed, as well as by developing our software to interpret the data needed to inform autonomous and assisted driving decisions. 
Our full-stack hardware and software autonomy solution for cars and trucks as well as our standalone lidar technology offerings have made us one of the leading technology partners for the world’s top OEMs.
Market Outlook 
There continues to be a worldwide trend towards mobility and e-mobility and with a focus on safety and autonomy, specifically next generation ADAS systems and highway autonomy for passenger and commercial vehicles. The roadmap from existing driver assistance and comfort features all the way to self-driving value can be built through improved vehicle situational awareness provided by sensors and software installed on the vehicle. 
Our products provide this situational awareness in a broad range of driving environments and allow for confident detection and planning at all vehicle speeds. Our portfolio encompasses sensor hardware, and perception and decision-making software that improve existing vehicle features and enable new levels of vehicle automation for consumer and commercial applications. 
The Society of Automotive Engineers (“SAE”) defines levels of automation as follows, which SAE updates from time to time:
•Level 0—No Driving Automation: In this level, the human is fully responsible for all dynamic driving tasks (“DDT”) at all times, even if an active safety system assists in the task. “L0” is defined as driver support features that are limited to warnings or momentary emergency intervention. Examples of warnings include blind spot warning or lane departure warnings. Examples of features with momentary assistance include automated emergency braking (“AEB”) and lane keep assist (“LKA”). These features are viewed as the basis of active safety, with AEB designed to reduce and/or mitigate the severity of low speed accidents, and LKA designed to prevent vehicles from crossing over into neighboring lanes or even worse, oncoming traffic.
•Level 1—Driver Assistance: In this level, the human is fully responsible for all DDT at all times, even if an active safety system assists in the task. “L1” is defined as driver support features that performs part of the DDT by executing either the longitudinal or the lateral vehicle motion control subtask, and disengages immediately upon driver request. Examples include lane centering support (“LCS”) or the more widely adopted adaptive cruise control (“ACC”). These features are viewed as comfort features, easing the driving load from the driver during extended highway drives.
•Levels 2—Partial Driving Automation: In this level, the human is fully responsible for all DDT at all times, even if an active safety system assists in the task. “L2” is defined as driver support features that performs part of the DDT by executing the longitudinal and the lateral vehicle motion control subtask, and disengages immediately upon driver request.
The term L2+ is often used for today’s higher capability systems, many of which add a driver monitoring system, such as camera or steering wheel sensing to ensure the human driver remains engaged, but require the driver remain attentive at all times. These systems are currently limited in Europe to certain operational design domains (“ODD”) 
where they are often limited by roadway type such as divided highways, but are more broadly allowed in the United States, China, and other regions. 
•Levels 3—Conditional Driving Automation: In this level, the automated driving system (“ADS”) performs the entire DDT while engaged. The driver is responsible to verify the operational readiness of the ADS, determine whether to engage the system, and becomes the fallback-ready user when the ADS is engaged - the human driver must take back full control of the vehicle when requested. The ADS permits engagement and operation only within its ODD. 
• Levels 4—High Driving Automation: In this level, the ADS performs the entire DDT while engaged. The driver is responsible to verify the operational readiness of the ADS, determine whether to engage the system, and becomes a passenger when the ADS is engaged (when physically present in the vehicle) - the human driver is not required to perform the DDT or be the DDT fallback-ready user. “L4” assures the ADS will determine how to achieve the minimal risk condition (i.e., degraded state). The human driver may perform the DDT after the ADS reaches its ODD limit. He or she may request that the ADS disengage, or may become the driver after a requested disengagement. The ADS permits engagement and operation only within its ODD.
•Levels 5—Full Driving Automation: In this level, the ADS performs the entire DDT while engaged. The driver is responsible to verify the operational readiness of the ADS, determine whether to engage the system, and becomes a passenger when the ADS is engaged (when physically present in the vehicle) - the human driver is not required to perform the DDT or be the DDT fallback-ready user. The ADS permits engagement under all driver-manageable on-road conditions. “L5” is essentially the same as L4, but without the ODD restriction. It is the designation for vehicles that when placed in automated driving mode, can drive everywhere and in all conditions without human intervention or even occupants. 
We believe the market is currently segmented in two distinct categories: (1) ADAS or driver-assistance systems, where a human is in the driving loop and responsible, at minimum, to be a safety fallback and in most circumstances directly control part or all of the dynamic driving tasks; and (2) autonomous driving, where a human is “out-of-the-loop” (colloquially, “hands off” the steering wheel and “eyes off” the road). 
Within these two segments, we believe the largest business opportunities exist in the areas of active safety and highway autonomy due to trends in safety technology standardization and consumer pain-point priority. These two applications have well aligned technology requirements that allow us to remain focused on a single product/solution that will allow OEM partners to achieve both. The broader autonomy market segment, specifically robo-taxis, represents strong long-term opportunity, but lidar technology must be seeded now during development even though high-volume production and deployment remains many years away. 
These trends and safety needs apply to both the passenger and commercial vehicle markets. The autonomy use case and business case for commercial vehicles are simple: reduce operational costs and increase efficiencies. Passenger vehicles are more complex since the ability to deliver autonomy is more focused on the consumer’s comfort and convenience. We are working to help OEMs and consumers achieve these goals, but with the proper level of safety included. 
Our initial focus for lidar technology is L3/L4 Highway Autonomy, and we aim to offer the sensing, perception, and function turn key system that will truly add value and give driving time back to the end consumer. This market is still developing, but we estimate it represents significant growth, and where we are a technology leader. In addition, vehicles enabled with our lidar will be capable of Proactive SafetyTM in which accidents are potentially completely avoided, which can benefit other autonomy solutions such as L0/L1/L2. 
Passenger Vehicles 
The passenger vehicle market is very large. We expect that approximately 100 million new passenger vehicles or more will be manufactured annually through 2030 and beyond. It is very difficult to replicate this volume in other markets, but it is also important to recognize that highway autonomy is not yet standard equipment. In order to realize a vehicle feature’s maximum societal benefits, the ultimate goal in the automotive industry is to achieve widespread adoption of next-gen safety and highway autonomous features in all vehicles. We expect a technology adoption ramp-up over time as automated functionality matures, costs and pricing are reduced, and consumers become more familiar with the full benefits and capabilities of a safe autonomy system. We believe there is a substantial market opportunity for our products when Proactive SafetyTM is coupled with autonomy due to the public benefit of the overall anticipated safety increase. 
ADAS 
ADAS volumes are primarily driven by both the European and North American markets. The European New Car Assessment Program (“NCAP”) requires a minimum level of crash mitigation functionality such as AEB (for vehicles, pedestrians, and cyclists), LKA, speed alert systems and other ADAS features for a vehicle to have a 5-star rating. Furthermore, the European Union is moving toward mandates of these advanced functions. 
The U.S. is less focused on mandates at this time and instead allows the U.S. NCAP (known as the “Stars on Cars” program) and designations such as the Insurance Institute for Highway Safety “Top Safety Pick” and “Top Safety Pick+” to drive adoption and provide consumers with an understanding of the vehicle’s advanced crash avoidance capability. Additionally, in working with the National Highway Traffic Safety Administration (“NHTSA”), 20 automakers pledged to voluntarily equip virtually all new passenger vehicles by September 1, 2022 with a low-speed AEB system that includes forward-collision warning. With global safety rating programs and the OEMs competing to deliver more safety and comfort features to their customers, it is reasonable to expect near complete adoption of ADAS functionalities in new vehicles produced by Europe, U.S., Japan, and South Korea by 2026. We expect adoption rates to increase significantly in China as well. 
We expect OEMs will demand Proactive SafetyTM and limited autonomy with the ability to upgrade functionality over time without hardware change. This expectation aligns well with the increasing number of OEMs developing new vehicle platforms that span their lineups. 
Proactive SafetyTM
While the increased application of existing ADAS technology should help reduce the number of accidents and fatalities, we believe there is significant room for improvement concerning standard ADAS and crash avoidance. Today, the ADAS systems are designed to mitigate or reduce the severity of accidents and only avoid them under certain low-speed or ideal environmental conditions. Data suggests that the number of automotive fatalities globally still exceeds one million annually and the social costs of accidents continue to exceed $500 billion in the United States alone. As the autonomy market matures, we expect that OEMs and global NCAP programs will extend the functionality to intersection and crossing scenarios, which requires wider fields-of-view and faster detection. Global safety rating programs are also considering night and low-light performance in the future, further pushing the existing technology’s limits. We believe there is a significant opportunity to be able to reduce collisions with a capable lidar sensing system and software which can enable an understanding of the environment, which can help to avoid collisions by taking over the steering wheel and braking systems proactively. We believe our lidar is capable of significantly increasing the effectiveness of these active safety systems and supports proactive safety and greater crash avoidance measures using our long-range, high resolution, wide field-of-view, and perception software to be able to detect pedestrians and cyclists in the most challenging and complicated environmental sensing conditions. Furthermore, high-speed safety performance, specifically AEB, is increasingly important as hands-free highway driving assist systems are further delivered to the market, and the vehicles take on more of the driving responsibility. 
Highway Autonomy 
Since inception, our focus has been to enable safe and ubiquitous autonomy and we view highway autonomy, in combination with Proactive SafetyTM, as providing the most value to the end consumer for the foreseeable future. The market appears to be trending in this direction, targeting hands-off and eyes-off operations in a more controlled setting than the urban environment. While there is a significant focus on investment and development of robo-taxi solutions, passenger vehicles continue to be a voluminous market, and we expect the continued growth of highway automated functions over the next several years. 
Commercial Trucking Market Outlook 
The amount of goods transported by trucking globally continues to rise year-over-year. The application of ADAS technology continues to grow and the interest in autonomy for transport is at an all-time high. The business case for trucking highway autonomy includes: lower operating costs, increased availability of the vehicles and time spent on the road. 
The first mandate for a vehicle AEB was in Europe in 2013, and there has been a growing application of the functionality since. Similar to passenger vehicles, Europe leads the market in a unified safety direction and has put mandates in place to drive lane keeping functions and expand the AEB functionality to include pedestrians and cyclists. This leadership is also a result of a market driven by the trucking manufacturers who set the technology distribution of vehicles and the ADAS vehicles and systems architectures. The trucking market in North America is driven by the fleet operators’ specifications and is fragmented. The lack of mandates from governing bodies has resulted in a market for ADAS that is very difficult to quantify and gain economies of scale across a small set of partners as is the case in Europe. As in passenger vehicles, we believe our lidar technology and sensing capability could greatly improve the L0 and L1 functionality for the trucking market as well. That said, our focus presently continues to be on L4 highway autonomous driving. 
L4 highway autonomy is the target ODD for trucking because that is where a majority of the physical truck’s time is spent. The sensing needs among Europe, North America, South Korea, Japan, and other regions globally all differ slightly, but have similarities in the requirement for (i) long range detection to aid in extra braking time, (ii) farther detection of lanes to aid in proper lane centering and placement of potential obstacles in the correct lanes, and (iii) the vertical field of view and high placement on the cab to support close proximity detection in front of the vehicle, as well as overhead obstacles (such as bridges and overhead signs). 
Robo-Taxi and Delivery Market Outlook 
The robo-taxi industry continues to evolve through investment and partnerships among technology companies, both established and startup, and mainstays from the automotive industry dominate the industry’s attention. This application is, however, the most difficult vehicle autonomy feature to solve for technically. It requires the ability to detect and classify hundreds of objects and predict motion for many of those objects, including pedestrians, electric scooters, and bicycles—all of which present as pedestrians, but move in very different ways. The environment consists of dynamic weather, steam from manholes and exhaust pipes, and oftentimes construction equipment causing dust and debris. Given the economic benefit an automated robo-taxi driving system could unlock, billions of dollars in funding and engineering efforts have been focused on developing solutions. The majority of the autonomous vehicle companies are operating in this space, awaiting a market that requires complex governmental support, funding for infrastructure, and a sensing and compute solution that must anticipate every possible mixed-traffic scenario. 
Additionally, the initial ODD only requires low to medium speed operation, which can be met with less capable sensors. We expect that ultimately, the ODD will need to expand to the highway as robo-taxis and automated shuttle services move people from city centers to the airport and back, in particular. We expect limited robo-taxi R&D programs will continue to operate in varying levels of development and testing the rest of this decade. 
Adjacent Markets 
Although not our primary focus, the adjacent markets offer use cases uniquely suited for and potentially served by our technology. Our goal is to scale our core markets and utilize our robust solutions to best serve these adjacent markets where it makes sense for us and our partners. One adjacent market we are focused on in the near-term is the Aerospace and Defense market. We have a partnership with Airbus UpNext, Airbus SE’s subsidiary created to give future technologies a fast-track. The primary goal of the partnership is to use our technology to increase aircraft safety and ultimately enable operation with automatic obstacle detection. Additionally, we have invested in and have a partnership with Robotic Research OpCo, LLC (“Robotic Research”), a global leader in autonomous mobility and robotic solutions. We are working with Robotic Research on opportunities to advance autonomy, and they have selected us as their long-range lidar provider.
Our Products 
Our Hydra, Iris and other products are described in further detail below: 
Hydra lidar sensors are dynamically configurable dual-axis scan sensors that detect objects up to 500 meters away over a horizontal field of view of 120° and a software configurable vertical field of view of up to 30°. High point densities in excess of 200 points per square degree enable long-range detection, tracking, and classification over the whole field of view. We plan to stop new production and shipments of Hydra in 2022 as we transition to newer products. 
Iris lidar sensors leverage the same core technology components in Hydra, but Iris is refined to meet the size, weight, cost, power, and reliability requirements of automotive qualified series production. Iris features two fully custom integrated circuits – driving both laser transmitter and receiver.
We expect to become a commercially viable long-range lidar supplier for automotive applications in L3 through L5 of vehicle autonomy, including full highway autonomy and urban and suburban autonomous driving. Iris is designed to be an efficient, automotive-grade, and affordable solution for series-production programs starting production in late 2022 or early 2023.
Autonomy Compute: Our electronic compute unit (“ECU”) is designed to accelerate the development of perception systems. Raw point-cloud inputs via ethernet, from up to four lidar sensors, are sent through a pipeline of processing layers to provide automated field coverage, enriched point-clouds, and ultimately, the perception outputs required for fusion and path planning. 
Software 
If a vehicle is to take an action on the road (e.g., accelerate, brake or steer) without human control, or even override human control, it must have an understanding of the driving environment. This understanding is called perception. The requirements for perception, and subsequently for the sensors providing necessary information underlying it, ultimately come from questions the vehicle system needs to have answered continuously to execute driving maneuvers safely in the real world. These questions are the same ones the human brain must continually assess to drive: 
•Where is the road, how is it organized into lanes, and which is the proper lane? 
•What driving rules apply to these lanes (e.g., lane change permission, speed, direction, traffic type)? 
•How is the vehicle moving now (speed, direction)? 
•What obstacles and other fellow travelers are in or near the roadway? 
•Where are these external objects (which lane, sidewalk, etc.), and how are they moving? 
With a confident and continuous understanding of the driving environment from our perception software, routes can be planned, risks can be assessed and actions can be sent to the vehicle’s control system. We, working closely with our partners, expect to deliver this full vehicle system capability. 
Core Sensor Software:  Our lidar sensors are configurable and capture valuable information extracted from the raw point-cloud to promote the development and performance of perception software. Therefore, core sensor software features help our commercial partners to integrate, control, and enrich the sensor data stream before perception processing. These features include: 
•Automatic sensor discovery to expedite system startup time; 
•Extrinsic calibration to automate multi-lidar geometrical alignment; 
•Proprietary middleware to streamline advanced user interaction with both our hardware and software; 
•Horizon tracking to automate region-of-interest scanning focused where it matters most, the road ahead; 
•Normal vector point attributes to associate common surfaces like drivable space quickly and accurately assess object headings without multiple frames; and 
•Velocity vector point attribute to provide both radial and crossing velocities, point-by-point within each frame.
Perception Software: Our plans for advanced perception software is to build on the core sensor software features and transform lidar point-cloud data into actionable information about the integrated vehicle and its environment. We anticipate these features to include: 
•Semantic Segmentation—Each measured point contains an object class attribute. This feature is expected to enable smart detection and tracking algorithms as well as intelligent vehicle reactions to different types of objects. 
•Instance detection and Tracking—Frame-level instance detection of objects, lane markings as well as road surfaces and free space combined with our highway-focused tracking algorithms are intended to provide reliable, safe and stable data for decision-making algorithms. 
•State Estimation—Continually predicting and correcting an object’s location, velocity, and orientation through lidar odometry, real-time mapping, and localization.
Sentinel: In March 2021, we announced our plans for a full-stack hardware and software solution, Sentinel. Development of Sentinel continues, and we plan to allow customers to purchase Sentinel as a complete “turn-key” solution that enables Proactive SafetyTM and Highway Autonomy functions or just components of Sentinel. We are in the preliminary designing and coding phase of the development and have not reached technological feasibility. We anticipate these features to include:
•Highway Autonomy:  In order to deliver highway autonomy to OEMs like Volvo, we are leveraging Zenseact and other ecosystem partners to further our internal understanding of the full autonomy systems. Highway autonomy will enable exit to exit functionality that takes full responsibility of the driving task even if the driver does not resume control in edge case emergencies. Early roll outs will be in limited highways, in limited environmental conditions and broaden as validation activities ensure safe ODD expansion. This capability is meant to allow passenger vehicles and commercial trucks alike to take occupants out of the driving loop so that they can utilize their time on other tasks. Further, highway autonomy systems will leverage over the air updates allowing them to grow even safer over time and expand their ODD through the life of the vehicle. 
•Proactive SafetyTM:  Our Proactive SafetyTM capabilities in development are expected to represent a new generation of vehicle safety, meant to enable accident avoidance instead of merely mitigating crash severity. It is expected to serve as a continuously monitoring system that assesses risk to the vehicle and recommends corrective actions and more importantly intercedes proactively when a crash is imminent. This feature is expected to utilize our extended range of confident situational awareness to broaden the ODD of legacy ADAS features, new safety features, and driver out-of-the-loop autonomous features. 
As of the end of 2021, we demonstrated initial Proactive SafetyTM functions as part of alpha prototype of Sentinel. The technical feasibility of the final Sentinel solution and perception software had not been established and these products are still in the designing and coding phase of development.
Competition 
The market for lidar-enabled vehicle features, on and off road, is an emerging one with many potential applications in the development stage. As a result, we face competition for lidar hardware business from a range of companies seeking to have their products incorporated into these applications. We believe we hold a strong position based on both hardware product performance and maturity, and also our growing ability to develop deeply integrated software capabilities needed to provide autonomous and safety solutions to our customers.
Although we believe our lidar sensor solution for automotive autonomy applications achieves the industry’s requirements and perception capabilities to enable safe hand-off, eyes-off driving, we face potential competition from Tier 1 companies, and other technology companies. We face competition from various emerging technology companies who we believe offer presently more limited solutions for niche applications and in certain cases are non-automotive grade solutions. We also compete with certain OEMs who have their own internal lidar products and approaches. In the meantime, our on-going software development will further differentiate our product offerings away from “lidar only” competitors. While lidar competitors may continue to emerge, we believe our high performance lidar with a strong intellectual property portfolio and software products help establish a competitive advantage for Luminar. 
Within the automotive autonomy software space, the competitive landscape is still nascent and primarily focused on developing robo-taxi technologies as opposed to autonomous software solutions for passenger vehicles. Other autonomous software providers include: (i) in-house OEM software teams (e.g. GM/Cruise and Ford/Argo); (ii) automotive silicon providers (e.g. NVIDIA and Intel/Mobileye); (iii) large technology companies (e.g. Google/Waymo and Amazon/Zoox); and (iv) newer technology companies focused on autonomous software (e.g. Aurora and TuSimple). We partner with several of these autonomous software providers to provide our Lidar and other products.
Beyond automotive, the adjacent markets, including delivery bots and mapping, among others, are highly competitive. There are entrenched incumbents and competition, including from China, particularly around ultra-low cost products that are widely available.
Intellectual Property 
Our success and competitive advantage depend in part upon our ability to develop and protect our core technology and intellectual property. We own a portfolio of intellectual property, including patents and registered trademarks, confidential technical information, and expertise in the development of lidar technology and software for autonomous vehicles. 
We have filed patent and trademark applications in order to further secure these rights and strengthen our ability to defend against third parties who may infringe on our rights. We also rely on trade secrets, design and manufacturing know-how, continuing technological innovations, and licensing and exclusivity opportunities to maintain and improve our competitive position. Additionally, we protect our proprietary rights through agreements with our commercial partners, supply-chain vendors, employees, and consultants, as well as close monitoring of the developments and products in the industry. 
As of January 2022, we had 109 issued patents (107 U.S. and 2 international), 93 pending applications (63 U.S. and 30 international), of which one U.S. application has been allowed. In addition, we have three registered U.S. trademarks, 16 registered foreign trademarks and five pending trademark applications. Our patents and patent applications cover a broad range of system level and component level aspects of our key technology including, among other things, lidar system, laser, scanner, receiver, and perception technology. 
Manufacturing Process 
We build and design certain critical components in-house, for example, our receiver ASIC and InGaAs photonic diode. We have an internal advanced manufacturing line located in Orlando, Florida, where we develop the manufacturing and testing processes, including capturing any related intellectual property, necessary to develop our products. Our manufacturing processes and knowledge are a key differentiator for us in the market. 
Extended component lead times and bottlenecks in the supply chain have created supply challenges for the entire market, and we expect these challenges to continue through 2022. 
In May 2021, we announced our series manufacturing partnerships with Celestica and Fabrinet. 
Research and Development 
Our research and development activities occur in Orlando, Palo Alto, Colorado Springs and Boston in the United States, and in Munich, Germany. Our Orlando site is primarily focused on developing sensor hardware, firmware, and controllers. Our Palo Alto and Germany sites are primarily focused on software development. The Colorado Springs and Boston locations create the custom ASIC chips and photonic diodes used in our lidar sensors.
Our research and development team is responsible for creating new technology and expanding lidar and perception software functionality. The team also designs the physical product, ensures it is designed for manufacturability and performs testing. The team also partners with our operations and supply chain functions to develop scalable commercial and reliable manufacturing processes and direct production material procurement. 
Sales and Marketing 
We use customer feedback to specifically tailor our product and approach to build and expand our relationships with potential commercial partners. We collect feedback directly from commercial partners to garner insights that help drive the business and product. We also work with analysts and higher education institutions to conduct studies, test and validate technology performance, providing key proof points for commercial partners considering our products. In parallel, marketing and communications drive our brand equity and narrative through ongoing announcements, campaigns, events, speaking opportunities, and public relations efforts. 
The automotive value chain characteristically involves research and feasibility studies, followed by long-term product development cycles including testing and qualification with the automakers, and long-term production supply. In general, automaker agreements do not guarantee potential volumes, vehicle models, or supply timing to suppliers during this product development cycle. Instead, typically, after initial research and feasibility agreements and extensive competitive negotiations, automakers enter into development agreements that establish collaborations or partnerships to develop and integrate technology into the automaker’s vehicles or platforms intended for series production, frequently accompanied by non-recurring engineering (“NRE”) projects. While these collaboration or partnership agreements provide automakers the right to terminate the relationship without purchasing any production volume, in practice, factors like difficulty of integrating complex technologies, sunken costs relating to NRE projects, impact on product roadmap, time to market, and risk of being unable to secure future supply creates significant cause for automakers to cancel collaboration or development agreements. Automakers typically only enter into blanket purchase orders or other definitive supply agreements with binding commitments and order fulfillment several months before production begins. We identify major commercial wins only when we have entered into a collaboration or partnership agreement and have reason to believe that such engagement is expected to result in future series production. Given the customary business practices in the automotive industry, there remains potential risk that our major commercial wins may not ultimately generate any significant revenue (See Item 1A, Risk Factors for definition of major commercial win and further discussion of risk).
Government Regulation 
Automotive safety regulation in the area of autonomy is split between two categories: (1) SAE Level 0-2 (including active safety, driver assist, and conditional autonomy); and (2) SAE Level 3-5 (partial through full autonomy) (commonly referred to as “higher autonomy”). In general, throughout the world, there is a positive legal environment that encourages consumer sale and use of SAE Level 0-2 functionality. The legal environment for SAE Level 3-5 functionality varies, generally encouraging the safe testing and development of higher autonomy functions, but restricting consumer use in personal vehicles and commercial use, as in automated trucking and taxis in many regions.
In the U.S., at both the federal and state level, nearly all SAE Level 0-2 functionality is permitted, while SAE Level 3-5 enjoys a positive environment for on-road testing and development, but mixed opportunities to deploy in consumer and commercial use. Federal regulation does not prohibit higher levels of autonomy today, but if National Highway Traffic Safety Administration deems an autonomy system unsafe, it would order a recall to remove vehicles from the road. Thus far, several U.S. states have expressly permitted SAE Level 4-5 levels of autonomy, while many remain silent, and others have laws that limit driverless operation. We believe regulations related to automotive autonomy technologies will continue to evolve to remove hurdles as state and federal regulators gain more experience with the technology. 
In Europe, China, and the rest of the world, most automotive safety is regulated by a common system under the United Nations Economic Commission for Europe (UN/ECE). Under current UN/ECE standards, SAE Level 0-2 functionality may be deployed with certain restrictions such as road type and with driver monitoring, but higher SAE Level 3-5 functionality is limited to testing only. Safety regulators continue to work on standards for autonomy, but we expect this development process to be slower than in the U.S. However, China has increasingly departed from the common UN/ECE standards and is more likely to create its own regulation allowing higher levels of autonomy in the nearer term with a timeline more aligned with the U.S.
Given the intense work in these regulatory areas, there is a positive environment for deploying our lidar technology and Proactive SafetyTM today in SAE Level 0-2 systems. While there is risk that SAE Level 3-5 systems may be delayed by regulation in some countries, we expect a workable path forward over the next several years as a more permissive regulatory and political environment develops.
Employees 
We have always prioritized the team’s importance, with values-based hiring that encompasses competency, ingenuity, and culture. Through multiple growth phases, we have drawn talent and leadership from the automotive, aerospace, consumer electronics and other technology industries to achieve our vision. As of December 31, 2021, excluding contractors, we had almost 500 full-time employees California, Florida, Colorado, Massachusetts, in the United States, Munich, Germany and other locations. None of our employees are represented by a labor union.
Our human capital resources objectives include, as applicable, identifying, recruiting, retaining, incentivizing and integrating our existing and new employees, advisors and consultants. The principal purposes of our equity and cash incentive plans are to attract, retain and reward personnel through the granting of stock-based and cash-based compensation awards, in order to increase stockholder value and the success of our company by motivating such individuals to perform to the best of their abilities and achieve our objectives. 
Corporate Social Responsibilities and Sustainability 
We are committed to active and responsible corporate citizenship. Our Corporate Social Responsibility (“CSR”) program is divided into seven elements (diversity and inclusion; human resources; finance/accounting; responsible sourcing; environmental, health and safety; trade compliance; and business ethics), each spearheaded by company leaders and subject matter experts in their respective areas. The CSR team supports, advises, and provides oversight for each element. We expect ADAS and automated driving technologies to provide strong social benefits including reducing roadway injuries and fatalities, including in urban areas, more efficient roadways that reduce commuting times and CO2 emissions, and offer improved productivity.
 Available Information
Our Annual Report on Form 10-K reports, along with all other reports and amendments filed with or furnished to the SEC, are publicly available free of charge on the Investors section of our website at www.luminartech.com or at www.sec.gov as soon as reasonably practicable after these materials are filed with or furnished to the SEC. We also use our website as a tool to disclose important information about the company and comply with our disclosure obligations under Regulation Fair Disclosure. Our governance guidelines, code of conduct and Board committee charters are also posted on the Investors section of our website. The information on our website (or any webpages referenced in this Annual Report on Form 10-K) is not part of this or any other report we file with, or furnish to, the SEC.
INFORMATION ABOUT OUR EXECUTIVE OFFICERS
Our executive officers as of March 1, 2022 are as follows:
Austin Russell, 26, has served as our President and Chief Executive Officer and as Chairperson and member of our board of directors since December 2020 and prior to this, served as President and Chief Executive Officer of Luminar Technologies, Inc. prior to its business combination with Gores Metropoulos, Inc. (“Legacy Luminar”) and as a member of its board of directors since founding Legacy Luminar. Mr. Russell developed his first visioning system at age eleven by building prototype supercomputers and optoelectronic systems with real-world applications in mind. He wrote his first patent application at 12, and over the next four years worked on a host of photonics and imaging related technologies before he later became an independent researcher at the Beckman Laser Institute. After being recruited to Stanford for Applied Physics, he was awarded the Thiel Fellowship at 17 to pursue Legacy Luminar full-time with a vision to develop a new kind of sensing technology to make autonomous vehicles both safe and ubiquitous.
Thomas J. Fennimore, 46, has served as our Chief Financial Officer since December 2020 and prior to this, held the same position with Legacy Luminar since July 2020. Prior to joining Luminar, Mr. Fennimore served as the Global Head of Automotive and the Co-Head of the Industrials Group at Jefferies Group, LLC from September 2014 to May 2020. From July 1997 to September 2014, Mr. Fennimore worked at Goldman Sachs in a variety of roles with increasing responsibility, most notably as Global Head of Automotive and Co-Head of the Asia Industrials Group. Mr. Fennimore holds a B.A. in mathematics and a B.S. in engineering from Swarthmore College.
Alan Prescott, 43, has served as our Chief Legal Officer and Corporate Secretary since April 2021 and is an automotive and autonomous industry legal expert, engineer, and 20-year veteran from top OEM and technology companies. Mr. Prescott joined Luminar from Tesla, where he spent four years, acting most recently as General Counsel.  Prior to Tesla, he led Uber’s Advanced Technology Group’s legal team as senior counsel, overseeing commercial, regulatory, litigation, privacy, and cybersecurity. Mr. Prescott’s career began at Ford Motor Company as a safety engineer before receiving his law degree from Georgetown University, after which he spent over ten years leading various legal operations within the automaker, concentrating on product development and manufacturing, as well as several years as Special Counsel to the General Counsel.
