Prompt: Summarize the business model from the following text. Answer with a continuous text and with fivehundredtwelve tokens at max. Set your focus on sources of revenue , the intended customer base , products , distribution channels  and details of financing. Use only information from the following the text:

Item 1. Business 
BACKGROUND OF BUSINESS COMBINATION
On June 9, 2021 (the “Closing Date”), Nautilus Biotechnology, Inc., a Delaware corporation (f/k/a ARYA Sciences Acquisition Corp III, a Cayman Islands exempted company and our predecessor company (“ARYA”)), consummated its previously announced business combination (the “Business Combination”) pursuant to the terms of that certain Business Combination Agreement, dated as of February 7, 2021 (the “Business Combination Agreement”), by and among ARYA, Mako Merger Sub, Inc., a Delaware corporation and wholly-owned subsidiary of ARYA (“Mako Merger Sub”), and Nautilus Subsidiary, Inc., a Delaware corporation (f/k/a Nautilus Biotechnology, Inc.) (“Legacy Nautilus”).
Pursuant to the terms of the Business Combination Agreement, on the Closing Date, (i) ARYA changed its jurisdiction of incorporation by deregistering as a Cayman Islands exempted company and continuing and domesticating as a corporation incorporated under the laws of the State of Delaware (the “Domestication”), upon which ARYA changed its name to “Nautilus Biotechnology, Inc.” (together with its consolidated subsidiary, the “Company” “New Nautilus” or “Nautilus”) and (ii) Mako Merger Sub merged with and into Legacy Nautilus (the “Merger”), with Legacy Nautilus as the surviving company in the Merger and, after giving effect to such Merger, Legacy Nautilus becoming a wholly-owned subsidiary of New Nautilus.
Upon the Domestication, all of the outstanding Class A and Class B ordinary shares of ARYA were exchanged for an equivalent number of shares of common stock of New Nautilus, par value $0.0001 per share (“Common Stock”). In accordance with the terms and subject to the conditions of the Business Combination Agreement, at the effective time of the Merger (the “Effective Time”), (i) each share of Legacy Nautilus outstanding as of immediately prior to the Effective Time was exchanged for shares of Common Stock of New Nautilus, and (ii) all vested and unvested options to purchase shares of Legacy Nautilus were exchanged for comparable options to purchase shares of Common Stock of New Nautilus.
Concurrently with the execution of the Business Combination Agreement, ARYA entered into Subscription Agreements (each, a “Subscription Agreement”) with certain investors (each, a “PIPE Investor”), pursuant to which the PIPE Investors subscribed for and purchased, and ARYA issued and sold to the PIPE Investors, on the Closing Date immediately prior to the Effective Time, an aggregate of 20,000,000 shares of New Nautilus Common Stock at a price of $10.00 per share (the “PIPE Shares”), for aggregate gross proceeds of $200,000,000 (the “PIPE Financing”). ARYA granted the PIPE Investors certain registration rights in connection with the PIPE Financing. Also concurrently with the execution of the Business Combination Agreement, ARYA entered into the Amended and Restated Registration Rights and Lock-Up Agreement with certain stockholders of ARYA and Legacy Nautilus, which obligated the Company to register the resale of certain shares of our Common Stock issued in connection with the Domestication and the Business Combination.
As of the open of trading on June 10, 2021, the Common Stock of the Company began trading on the Nasdaq Global Select Market (“Nasdaq”) under the symbol “NAUT.”
Unless expressly indicated or the context requires otherwise, the terms “Nautilus,” “New Nautilus,” the “Company,” the “Registrant,” “we,” “us” and “our” in this Form 10-K refer to Nautilus Biotechnology, Inc., the parent entity formerly named ARYA Sciences Acquisition Corp III, after giving effect to the Domestication and the Business Combination, and as renamed Nautilus Biotechnology, Inc., and where appropriate, our wholly-owned subsidiaries (including Legacy Nautilus).
OVERVIEW
We are a development stage life sciences company creating a platform technology for quantifying and unlocking the complexity of the proteome. Our mission is to transform the field of proteomics by democratizing access to the proteome and enabling fundamental advancements across human health and medicine. We were founded on the belief that incremental advancements of existing technologies are inadequate, and that a bold scientific leap would be required to radically reinvent proteomics and revolutionize precision medicine. Our vision is to integrate our breakthrough innovations in computer science, engineering, and biochemistry to develop and commercialize a proteome analysis platform of extreme sensitivity and scale. To accomplish this, we have built a prototype of our proteome analysis system, an instrument to perform massively parallel single protein molecule measurements which will be further developed to deliver the speed, simplicity, accuracy, and versatility that we believe is necessary to establish a new gold standard in the field. 
The human proteome, the make-up of all the proteins in a human, is among the most dynamic and valuable sources of biological insight in modern-day science. Unlike the genome, which is largely unchanging throughout an individual’s lifetime, the proteome is an ever-changing source of biological information. Our proteins directly control and determine the functions of our cells, yet we lack the ability to measure all of them with the ease, breadth and sensitivity that is used to measure DNA 
today. We believe that deep characterization of the proteome will have the potential to unveil an entirely new layer of complexity and valuable biological information that may have significant implications across life sciences, healthcare and drug development. Approximately 95% of FDA-approved drug targets are proteins, and yet today we still lack the ability to routinely read and quantify all of the proteins in our cells, or to fully map the downstream changes and modifications to those proteins which may define their biological function.
By leveraging our novel design coupled with advanced machine learning software, we believe our Nautilus platform, which includes our end-to-end solution comprised of the proteome analysis system, consumables, and software, has the potential to rapidly and reproducibly identify approximately 95% of proteins in a sample from virtually any organism, and could have the ability to detect and map the diverse landscape of modifications on those proteins. We believe that unlocking proteomics has the potential to create a long-term transformation of basic science, translational research, and healthcare. 
Current proteomics platforms for broadly quantifying the abundance of proteins within samples generally fall into two classes: affinity-based and mass spectrometry-based methods. For years, these methods have facilitated novel drug development and improved diagnostics. As with most technology platforms however, these also suffer from distinct limitations that make simple, high-throughput, ultra-deep characterization of the proteome challenging. Mass spectrometry approaches have tremendous flexibility and thus have been applied to a wide range of applications, however their use requires a trade-off to be made between either depth or throughput; meaning that a researcher can either look at one sample in a deep analysis or at many samples in a shallow analysis. Additionally, challenges in ease of use and sensitivity have limited the ability of mass spectrometry-based methods from easily, broadly and quickly characterizing the entirety of the proteome. Affinity-based approaches use the binding attraction of antibodies to proteins to capture and measure protein targets in parallel. These technologies can provide greater sensitivity, however this approach is directly dependent on the availability of high quality, highly specific and sensitive affinity reagents, which can limit the scale, reproducibility and accuracy. Consequently, we believe researchers are forced into an unattractive trade-off between the number of samples in a study and the depth and breadth of the analysis. These trade-offs limit researchers’ ability to advance characterization of the proteome to match the current, and highly valuable, characterization of the genome. We believe the limitations of both platforms have prevented progress towards achieving comprehensive proteome and deep proteoform characterization. If detecting and quantifying the complexity of the human proteome were as simple and easy as detecting an entire human genome, we believe a new set of questions could be asked: 
•Down to the very low frequencies of expressed proteins, how are healthy tissue cells different from diseased cells?
•What will a comprehensive map of nearly all proteins by organ tissue type tell us about our biology?
•What specific patterns of protein modifications are present in disease, and why?
•What happens to our proteome when we get sick, and how does it change with treatment?
We believe that our Nautilus platform has the potential to position us to answer these questions, and many others that have not previously been possible to fully investigate. Due to the extensive applications and broad potential of large-scale proteomic characterization, we believe the proteomics market is currently among one of the largest untapped opportunities in the biological sciences today. The existing proteomics research market is currently estimated to be approximately $25 billion annual spend as of 2021, made up primarily of mass spectrometry and affinity-based quantification methods. Over the longer-term, the proteomics market is expected to reach approximately $50 billion by 2027, representing a compound annual growth rate, or CAGR, of 12% over the six-year period. Further, we believe there are substantial adjacent opportunities across translational research, drug target discovery, precision medicine development, clinical diagnostics, and other disciplines such as food and environmental science. 
We plan to initially target the life sciences proteomics research market and are currently entering the first phase of our product development and commercialization strategy. In this first phase, we are focused on developing partnerships with key biopharma companies and leading academic institutions to create a founding group of collaborators that will gain experience with our technology, jointly publish research using our Nautilus platform, and generally help validate our initial applications. As of the date of filing this Annual Report, we have partnerships with Genentech, Amgen, and The University of Texas MD Anderson Cancer Research Center. In the second phase we plan to launch an early access program to an expanded group of customers. We believe these customers will become important reference sites and key influencers that aid in the market adoption of our Nautilus platform, and will help us build a strong value proposition ahead of full commercial launch. In our third phase of commercialization, we intend to execute a broad commercial launch of our Nautilus platform including the introduction of our proteome analysis system, which is an integrated fluidics and optics system for massively parallel single protein molecule detection, accompanied by consumable reagents and analysis software, in direct sales to customers across academia and industry. The launch of our proteome analysis system is expected to be done with a multi-year product roadmap of system enhancements and new applications designed to help our customers achieve their research objectives and expand the 
utility of our Nautilus platform. We also plan to leverage our machine learning software to build a data analysis and insights engine that improves over time as we grow our data sources and the analysis learns to deliver better accuracy and identify new potential discoveries. We believe by following this methodical pathway, we can optimize the development of our Nautilus platform, establish a steady flow of validating publications, appropriately scale our operations, deliver exceptional customer experiences, and help ensure we are delivering long term value and revenue growth. 
Since inception in 2016, we have worked diligently to secure a strong intellectual property portfolio, and we have successfully filed and obtained numerous key patents. Our management team also brings a unique combination of experiences from the fields of technology and life sciences, with a proven track record of building successful businesses based on novel technology. Our company is a highly interdisciplinary organization, and as of December 31, 2021 we were comprised of approximately 113 employees, with 36 of such employees holding a Ph.D. Our organization is driven by the pursuit of deep, hard science, and our Scientific Advisory Board is comprised of world-renowned scientific leaders that support our vision.
OUR STRENGTHS
•Highly disruptive proteomics technology. Our Nautilus proteome analysis platform is designed to be a disruptive, single protein molecule analysis technology of extreme sensitivity, scale, and ease-of-use. Leveraging a novel system architecture, advanced machine learning and algorithms, we believe our Nautilus platform has the potential to identify substantially all proteins in a sample from almost any organism. We have designed our Nautilus platform technology by substantially reimagining methods of protein analysis, rather than an incremental or evolutionary advancement. We refer to Nautilus’ framework for what we believe to be a fundamentally different approach to protein analysis as Protein Identification by Short-epitope Mapping (PrISM). We believe that the prototype of our Nautilus proteome analysis system has also demonstrated the ability to detect the patterns of modifications made to proteins, while preserving the context of those modifications on the molecule where they exist, a capability that we do not believe is possible with existing affinity-based or shotgun mass spectrometry-based methods. 
•Novel end-to-end proteomics detection platform of extreme sensitivity. We aim to be the first commercially available proteomics detection platform technology and end-to-end solution to decode and quantify virtually the entire proteome, including the variations and modifications of proteins. Our Nautilus platform consists of instruments, reagents and software that we believe has the potential to deliver broad proteomic profiling to the market and potentially unlock the vast, dynamic, and valuable biological information contained in the proteome. Not only would this enable us to have a significant technical advantage, but we believe it may also allow us to leverage a diversified revenue model that could be highly recurring in nature. With each instrument sale, there is expected to be an accompanying recurring stream of consumable sales, in addition to service, support and software creating a comprehensive proteomics solution.
•Open and customizable technology platform. Our Nautilus platform is designed to be compatible with a wide variety of affinity binding reagents. We believe that this flexibility allows the system to be ‘tuned’ in response to the profile of binding reagents introduced. With a labeling kit, our system is designed to be able to use a wide range of reagents that have been created by biopharma, academia, or leading commercial affinity reagent manufacturers. It also creates the opportunity to partner with third-parties on the development and supply of affinity reagents. To that end, in the fourth quarter of 2021 we initiated a strategic partnership with Abcam, a world leader in the design and production of assay kits, reagents, and antibodies. This type of development and supply agreement is expected to provide Nautilus with antibodies additive to the affinity reagents we are creating internally and serves to highlight the flexible nature of our technology. 
•Immense data production capacity coupled with machine learning can unlock new proteomic insights. We have designed the Nautilus platform to create and process a vast amount of proteomic data. The Nautilus platform is expected to generate up to approximately 20 terabytes of digital protein data per run, which will then be decoded using our proprietary machine learning algorithms and cloud-based data processing infrastructure. As we expand and enrich our database with increasing amounts of digital proteomic data over time, we plan to deploy our machine learning algorithms to continuously improve and benefit from each new experiment generated with our Nautilus platform. We believe that this feedback loop has the potential to deliver future value to our customers through the continuous improvements in our analytics, thereby encouraging the analysis, and re-analysis, of more samples through our Nautilus platform to benefit from these advancements. 
•Commercial model with clear market entry point, designed to support a wide variety of customers and applications. Many successful life sciences research tools companies with disruptive technology have employed a business model similar to our planned commercial model. However, we believe a key advantage for us is the near-term commercial 
opportunity of capitalizing on the existing mass spectrometry-based proteomics marketplace estimated at over 16,000 installed systems. Our price point is expected to be in-line with mass spectrometry system budgets allocated for broad scale proteomics applications, and thus with a premium instrumentation average selling price, or ASP, we plan to operate with a very efficient sales model. Further, since the early days of our product development, we have consulted with biopharma companies, academic institutions and research organizations to inform our product development plan and specifically address our target customer needs. These customer segments were estimated to spend approximately $195 billion in 2021 in R&D activities across a variety of settings, from basic sciences to translational and clinical research.
•Our Nautilus platform technology could position us as a leader in a large initial life sciences research market and provide a path to the clinical diagnostics. The global proteomics market is estimated to be approximately $25 billion annually as of 2021 and is expected to grow at an estimated 12% CAGR from 2021 to 2027. Furthermore, we believe our Nautilus platform has the potential to facilitate a broader transformation across life sciences and healthcare, and therefore significantly augment our total addressable market over time. We believe there are multiple high-value applications in precision and personalized medicine, drug discovery, and clinical diagnostics that can be unlocked by accurate, reproduceable, and cost effective proteomic profiling. As the proteomics market continues to mature, and if our technology is validated across translational research applications, we believe our Nautilus platform could transfer well into the clinical setting prior technologies have thus far been unable reach.
•Our experienced, multidisciplinary team brings together a group of individuals with diverse backgrounds to disrupt the field of proteomics. Nautilus’ leadership team represents a unique and valuable hybrid of technology and biotech experience. Several members of the executive team and board of directors held leadership roles at Illumina and Isilon, and helped to guide strategy and manage execution both before and throughout the rapid growth and success for those businesses. We view the core design thesis behind the Nautilus platform technology development as a non-traditional approach to new product development within life sciences that requires thinking at the intersection of three unique disciplines not often found together—life sciences, computer and data sciences, and physical sciences and engineering. As such, we have assembled a team of individuals with experience across many different disciplines, including protein biochemists, nano-fabrication engineers, software and machine learning engineers, single-molecule biophysicists, optical engineers and others, all working together toward our common goal.
OUR STRATEGY
•Drive adoption of our Nautilus platform by providing the life sciences industry with access to the proteome. We believe our Nautilus platform has the potential to provide value across the life sciences ecosystem as the first end-to-end solution capable of substantially quantifying the proteome. The utility and potential applications are expected to be broad and serve basic research and discovery, translational and clinical research, and clinical diagnostic market segments. We intend to drive adoption of our Nautilus platform through a three-phase commercial strategy that begins with an initial partnership and collaboration phase with biopharma companies (such as our existing relationships with Genentech and Amgen), academic institutions (such as our existing relationship with The University of Texas MD Anderson Cancer Center and others) and research organizations where we aim to jointly publish data and validate our Nautilus platform, followed by a pre-sales or early access program to drive awareness and demand, and finally culminating in a full commercial launch. 
•Continuously innovate and scale our Nautilus platform’s capabilities to enable further advancement of proteomic research. Through both internal R&D projects and external collaborations with our customers and partners, we plan to continuously innovate and develop new products, applications, workflows, and analysis tools that simplify and accelerate the ability for our customers to generate new sources of proteomic data and drive novel biological insights. We believe our sustainable advantage could come from a continued stream of development and commercialization of new products and applications using our core technology to help our customers succeed in their research endeavors. We believe if our customers win, we all win.
•Multiple pathways to build and expand our manufacturing capacity to support our commercial launch and the sustained growth of our business. Our technology is comprised of many off the shelf component parts that help to create efficient sourcing and manufacturing processes. We have established a manufacturing process for our technology utilizing a combination of both external contract manufacturers and internal resources based in our San Carlos, CA facility, with the ability to support substantially all of our current core activities during development. We believe there are many potential options we can use in order to increase the manufacturing and production capabilities 
for our products, including expanding our outsourced manufacturing and supply to multiple suppliers to ensure our quality and production capacity will meet our commercial plan. 
•Build long-term value by leveraging the open design of our Nautilus platform to create an ecosystem of products and services based on our core technology. Our Nautilus platform is compatible with a wide variety of protein affinity binding reagents, which we believe will allow us to create a broad menu of applications compatible with our technology. Our Nautilus platform is also designed to be highly customizable, which we believe will allow us to create an infrastructure that enables our customers to design their own custom solutions and applications. We believe that commercializing our technology with a set of standard product applications, alongside the ability to maintain a flexible approach for designing new applications with our customers, could potentially lead to an entire ecosystem of products and services leveraging our core technology. 
•Expand adoption of our Nautilus platform into new markets. Our market entry strategy involves identifying markets that are constrained by their inability to access comprehensive proteomic information, which we believe can be addressed by our Nautilus platform. We recognize that these opportunities extend into ancillary markets across life sciences, including clinical and translational research, and clinical diagnostics, where we believe there are substantial unmet needs our Nautilus platform can address in the future. We expect to drive expansion into these adjacent markets by developing and validating new product configurations and workflows targeting high impact applications, either by adapting our existing workflows or by partnering with leaders in those markets to develop workflows that address their immediate needs and will provide broader general value for other customers in that market segment.
A PRIMER ON PROTEOMICS
Over the past decade, the study of genomics, or DNA, and transcriptomics, or RNA, have been central to drug development and healthcare. Proteomics is the next step in the study of biological information systems and is believed by many to be one of the most important disciplines for exposing disease-causing protein pathways, uncovering new drug targets, highlighting novel therapeutic indications and identifying clinically relevant biomarkers for use in precision medicine.
Molecular profiling techniques, such as NGS, have led to widespread genomic characterization and sequencing. While this information has augmented our knowledge of biological systems, the detail at the protein level remains largely unknown. Proteomics seeks to address this gap, and is an emerging scientific field that involves the identification, characterization, and quantification of proteins in whole cells, tissues, or body fluids. 
The proteome ultimately drives the function of a cell and tissue, and therefore it dictates the physically observable characteristics known as the phenotype. The proteome undergoes dynamic changes as it continuously responds to chemical signals, blood-borne mediators, temperature, drug treatment, and developing disease over time. This complex interplay of factors contributes to the complexity of proteomics research. However, the detailed and complex information provided from proteomics has the potential to help in identifying novel and causal drug targets and to enable more efficient and effective drug development. A few examples of the way proteomics may lead to novel insights are highlighted below.
•Better understanding of biology. Protein research contributes to a better understanding of how molecular information controls and influences an individual’s physiology.
•Identification of novel drug targets. Cellular function and dysfunction is driven by our proteins; increasing our ability to directly measure even the rarest proteins involved in disease may increase the likelihood of identifying new drug targets.
•Patient stratification. The separation of patients into groups with similar molecular features that may be more likely to respond to specific therapeutic treatments.
•Prediction of disease and treatment outcome. The identification of biomarkers that can assist in the early diagnosis of diseases, inform prognosis or monitor the efficacy and safety of ongoing treatments.
•Wellness: from health to disease. Biomarkers can monitor and guide individuals to tailor lifestyle choices to maximize health and avoid the onset of diseases before they develop.
Not only would advancements in the field of proteomics have the potential to directly unlock new insights on their own, but they would also have the potential to increase the value of data and insights generated in related fields such as genetics, gene expression, and metabolism. 
OUR MARKET OPPORTUNITY
We believe that our Nautilus platform has the potential to be uniquely positioned in the proteomics market. In our mission to democratize proteomics, we see initial applications in precision and personalized medicine, clinical diagnostics, as well as in machine-learning powered drug discovery. However, we believe that the opportunity could extend far beyond this.
Market Environment
At Nautilus, we recognize the need for a radical breakthrough in proteomics. 
Since 2002, global R&D expenditure has increased close to three-fold and is expected to reach approximately $230 billion by 2026 according to EvaluatePharma’s 2020 report. Despite such investments, the number of new drugs approved each year has failed to increase proportionally. Additionally, it takes more than 10 years to bring a drug to market, and the cost has grown significantly in the past decade from approximately $1.2 billion in 2010 to approximately $2.0 billion in 2019. The increasing cost, time and complexity of drug development have driven down the rate of return on R&D to less than 2% in 2019 for the 12 leading biopharmaceutical companies analyzed in a 2020 report by the Deloitte Center for Health Solutions.
Approximately 95% of FDA-approved drug targets are proteins, and most other drugs interact with, or are influenced by signal transduction cascades mediated by proteins. As such, an understanding of the proteome is paramount to understanding pharmacology. 
As existing approaches only allow us to routinely quantify a fraction of the proteome, biopharmaceutical companies have become increasingly adept at identifying possible targets within what is currently observable, and as such, many viable targets have been exhausted. Despite the many hundreds of thousands of biomarker research studies estimated to have been published to date, there are only approximately 100 unique pharmacogenomic biomarkers with FDA approval for use with therapies today. This number of approved biomarkers is alarmingly low, and further highlights the shortfall of attempting to predict a protein biomarker’s expression level and function primarily from genetic data. Unfortunately, researchers have been forced to use this method, given the availability of powerful tools in genomics without the corresponding power and breadth of tools available in proteomics. With an advancement such as the Nautilus platform, we believe researchers will have the power to deeply and comprehensively measure the physical proteins at the root of disease, dramatically increasing the potential to identify more clinically meaningful biomarkers with greater precision in the practice of medicine. A breakthrough increase in throughput will enable researchers to more deeply measure large cohorts, thereby powering studies at the scale required to quickly and cost-effectively discover new critically important biomarkers.
The inability to easily and reliably quantify the proteins that drive every aspect of human physiology has been a fundamental hindrance to a greater understanding of cellular and molecular biology. With this in mind, we aim to democratize proteomics to make it possible for the broader scientific community to undertake a wider range of high-value scientific inquiries, thereby accelerating research and ultimately enhancing our fundamental understanding of biology and the mechanisms of disease.
The Missing Piece: The Proteome
Improvements in NGS technology have greatly enhanced the understanding of the genome, but when contemplating the number of proteins that can arise from a single gene and their role in the regulation of biological processes, both physiological and pathological, we believe that a better understanding of DNA is simply insufficient. Beyond the genome lies a vast multi-level network of biological interactions with important ramifications across the organism that remains coded and hidden within unique protein patterns. Many scientific and industry leaders believe these patterns may hold the key to a deeper understanding of biological processes at both a molecular and a systems level. 
From the day we are born to the day we die, proteins are responsible for regulating all aspects of our physiology. The genome, which represents the complete set of genes within each organism, remains largely unchanged throughout the course of life. Over the years, it has been estimated that humans possess approximately 20,000 protein-encoding genes, many of which have been well characterized. However, to coordinate the myriad of processes that occur within organisms at all times, the genome has evolved multiple ways to generate further biological complexity. DNA genes are expressed in the form of RNA transcripts, which control the expression and regulation of these different genes in the cell. These RNA transcripts are then translated into individual proteins, and protein isoforms, which are subtle variations of the individual proteins themselves. Scientists have estimated that there may be as many as 70,000 or more human protein isoforms. The resulting proteome is not only highly dynamic and in a constant state of flux by regulating the quantity and type of each protein isoform, but it also 
exhibits great diversity across cells and tissues. This complexity, which governs all biological processes, both healthy and sick, cannot be captured or characterized routinely by current methods.
However, the molecular complexity of our proteome doesn’t stop here, it actually grows dramatically even beyond the abundance of protein isoforms that are dynamically rising and falling. After a protein isoform has been translated, it can be modified further by biological processes that more precisely control that protein isoform’s location, specific activity, or interaction partners, and these downstream changes are together called post-translational modifications. There are a wide variety of post-translational modifications known today, which result in a tremendous increase in molecular complexity by creating different “forms” of the same basic protein, known as “proteoforms”. In total, our original 20,000 protein-coding genes are estimated to produce as many as 6,000,000 different proteoforms, as illustrated in the figure below. The existence of these proteoforms indicates that there may actually be well over two orders of magnitude (or 100 times) more complexity present across our proteome than there is across our genome. It is strongly suspected that it is within this proteoform space of molecular information that fundamental biological processes are present that govern our cells, and our molecular health.
Post-Translational Modifications Create Multiple Forms of Proteins That Are Estimated to Contain Over 100 Times More Information Complexity Than the Coding Genes in the Genome
While the past several decades have seen advances in proteomics technologies, typical solutions only capture a fraction of the proteome in samples derived from blood or cells, as illustrated in the figure below. On the left, using mass spectrometry-based methods, approximately 8% of proteins are routinely detectable from blood and approximately 30% are routinely detectable from cells. On the right, there is currently no method to easily detect and map the landscape of proteoforms, which would allow for the exploration of the estimated 6,000,000 different forms and patterns of modified proteins serving some biological function. Furthermore, shortfalls in the ability of bioinformatics to predict the existence as well as the function of genes have further illustrated the need for enhanced protein analysis techniques. Today, we believe the field of proteomics is at 
the very beginning of a significant growth phase. We are of the firm belief that every scientist should have access to the proteome, including proteoforms, in the same way that access to the genome has been made broadly available over recent years.
Current Technologies are Unable to Routinely Access the Full Proteome or Detect Proteoforms
Market Opportunity
Due to the extensive applications and broad potential, we believe that the proteomics market represents one of the largest untapped opportunities in the biological sciences today. According to Allied Market Research, the global proteomics market was valued at approximately $25 billion as of 2021. This encompasses only the fraction of the proteomics market that is currently available to us via mass spectrometry and other quantification methods and does not include diagnostics. The overall proteomics market is projected to reach approximately $50 billion in 2027, representing a CAGR of 12% for the six-year period.
We believe that as the proteomics market evolves, substantial adjacent opportunities will arise due to the potential applications in not only precision and personalized medicine, clinical diagnostics, and machine-learning powered drug discovery, as well as other disciplines such as food and environmental science. Within the biomedical sciences, the application of proteomic technologies to clinical specimens has the potential to revolutionize multiple aspects of the diagnosis and treatment of many diseases, propelled by biomarker discovery and validation of personalized therapies which we believe will greatly increase the power of prediction, diagnosis and prognosis.
Existing Proteomics Technologies and Shortfalls
Over the past decade, the importance of proteomics in the field of diagnosis and drug research & development has increased dramatically due to the direct biological relevance of analyzing the interaction of proteins in living organisms. However, the analysis of the proteome is substantially more complex than the analysis of the genome or transcriptome. Unlike DNA and RNA, proteins themselves cannot be amplified. Consequently, measurement tools must address the challenges of sensitively detecting the minute quantities of low frequency expressed targets. This challenge is exacerbated by the exceptionally large dynamic range of proteins in both cells and in blood spanning more than seven orders of magnitude. For example, some critical and influential proteins such as transcription factors may be present with only a few copies per cell, whereas abundant proteins such as cytoskeleton or ribosomal proteins may be present in millions of copies per cell. Quantifying both the low frequency and the abundant proteins within a single sample is very challenging and stands in stark contrast to genome or transcriptome analysis which only contends with a dynamic range of approximately three orders of magnitude. Furthermore, the biochemical and physical diversity of proteins far exceeds that of DNA or RNA as proteins are created from 20 highly distinct amino acids, whereas genes and transcripts are created from only 4 distinct nucleotides. These inherent complexities have hampered progress in the development of life science tools that can sensitively and comprehensively quantify the proteome. Additionally, the ability to identify unique proteoform composition and frequency in a single complex sample is not achievable today. Currently available tools can be broadly segmented into mass spectrometry-based and affinity-based methods.
Mass Spectrometry-based Approaches
Mass spectrometry is a powerful tool for the measurement of proteins and has progressed the field of proteomics immensely, similar to the impact that Sanger sequencing had to the founding of large-scale genomics research. However, for the powerful data that is generated, current mass spectrometry workflows still remain complex and time consuming. The mass-spectrometry workflows and processes are not fully automated requiring skilled professionals to prepare samples and operate instruments, which limits the impact of these powerful technologies. Mass spectrometry is also known to have poor sensitivity to detect proteins present at low frequencies within biological samples, which is where many believe important drivers of biology exist. Lastly, the most widespread approach called shotgun mass spectrometry, requires proteins are first broken apart into small pieces called peptides in order to measure them. This detection method can only measure the individual protein fragments, and is therefore unable to identify specific patterns of post-translational modifications and proteoforms visible on intact proteins across a sample. Despite these challenges, there has still been a strong appetite for protein data given its importance in biology and drug development, and the proteomics research marketplace is estimated to have over 16,000 installed mass spectrometry systems today.
Limitations with Affinity-based Approaches
Where mass spectrometry-based approaches have been widely used for broad scale protein discovery applications, affinity-based approaches have generally been used for targeted protein measurements. Affinity-based protein detection commonly utilizes affinity binding reagents that are designed to be very specific to an individual protein target that is already known to the 
researcher. Additionally, the ability of an affinity reagent to selectively bind to its target may also be impacted by protein specific factors, such as the protein’s folded structure and orientation. Lastly, affinity-based approaches intended to target more than one protein at once in a sample commonly require a different affinity binding reagent for each target. Despite decades of ongoing efforts, there are still nowhere near the number of affinity-reagents in existence today to attempt to measure the full proteome. In general, affinity-based approaches are most useful when the end user has a relatively small pre-defined set of targets they want to measure, and because the affinity reagents themselves only detect a small portion of the intended target, this method is also not capable of resolving unique proteoform patterns at the single protein molecule level today.
THE NAUTILUS APPROACH
Our Guiding Principles
Nautilus is driven by a desire to enable the research community to rapidly and comprehensively access and quantify the proteome, thereby transforming our ability to examine disease mechanisms, and develop new therapeutics and diagnostics. This mission is guided by a recognition that major advances in proteomics have generally lagged behind genomics, primarily due to a lack of available tools for measuring the proteome as easily or completely as one can measure the genome and transcriptome.
We believe that evolutionary or incremental improvements to existing technologies will not suffice; that a fundamentally new approach is required to unlock this large opportunity in biological science. In pursuit of that mission, we are developing our innovative Nautilus platform to be an end-to-end single protein molecule analysis solution composed of instrumentation, reagent consumables, and software that processes a sample and returns valuable and unique biological data and insight. We have designed the Nautilus platform to enable extreme sensitivity and scale, without compromising on ease of use. Leveraging a unique architecture and advanced machine learning software, we believe our Nautilus platform has the potential to identify substantially all proteins in a sample from almost any organism. 
We view many of the core ideas underlying the Nautilus platform as “counterintuitive”, as it required innovations at the intersection of three distinct disciplines not often found in harmony: life sciences, computer and data sciences, and physical sciences and engineering. We have designed the Nautilus platform to integrate a variety of both computational and experimental approaches, diverse measurement modalities, and the best available analytical tools to accelerate biomarker discovery and precision medicine. Several Nautilus platform technology elements (e.g., cloud computing and machine learning) are disciplines that have now sufficiently matured to create this timely opportunity for Nautilus to pursue the deep, hard science required to bring to market a potentially revolutionary capability that we believe will help democratize access to proteomics data.
Our Nautilus Platform Design Criteria
To achieve our ambitious goals, and to meet the unmet needs of scientists and researchers, we recognized early on that we would need to tackle the deep, hard, novel science required to innovate and commercialize a fundamentally new detection technology capable of reading and quantifying the proteome and associated proteoforms. As such, we designed the Nautilus platform – from the ground up – to accomplish the following objectives:

Nautilus Platform Attribute: | | Nautilus Platform Benefit: 
Easy-to-Use | è | Any Lab Can Run It 
Sensitivity and Dynamic Range | è | Comprehensive Measurement 
Rapid Run Time | è | Days Not Weeks 
Reproducible and Robust | è | Path to the Clinic 
Scalable and Flexible | è | Accommodates Low & High Throughput
Complete | è | No Missing Data 

A core design criterion was that the Nautilus platform needed to be sufficiently easy-to-use so that virtually any lab could benefit from using it, not just labs that are explicitly focused on proteomics or analytical chemistry.
Next, the Nautilus platform needed to be ultra-sensitive. Unlike NGS technologies, where one can leverage natural processes and enzymes (e.g., polymerases) to amplify DNA and RNA, proteins cannot be amplified from the original molecule. To achieve the goal of measuring the complete proteome, scientists and researchers needed a new analysis method with unprecedented sensitivity.
In addition, the process needed to be reproducible and robust, maximizing the chance that the results derived in one experiment are the same as the results derived in subsequent experiments. 
It must also be complete. One of the largest challenges with existing “shotgun” proteomics technologies is that replicate analyses are likely to sample different subsets of the proteome. 
In order to fully support the wide-ranging needs of our future customers, the platform can also support multiple run configurations. Our design accommodates both low throughput and high throughput run configurations, and will also employ in-lane sample multiplexing to enable our customers to meet the high-volume data production needs of large-scale studies or core facilities.
Importantly, the Nautilus platform needed to be fast and able to analyze tens of thousands of samples in a reasonable time period. 
It also needed to be integrated, allowing a biologist to put a sample in the instrument and get data out without additional intervention.
With these objectives identified as our core design criteria, we set out to create a transformative technology with the potential to achieve all of these criteria. The resulting Nautilus platform has embodied many technical innovations across sample preparation, reagent consumables, instrumentation, and downstream protein analysis. However, we believe there are four critically important key technical innovations that, when brought together, make the achievement of our Nautilus platform design specifications and benefits possible:
A Single Protein Molecule Flow Cell
The Proteome Analysis System: An Integrated Multi-cycle Optical and Fluidics Instrument
A Novel Class of Affinity Reagents for Efficient Whole Proteome Analysis
Machine Learning Protein Decoding Analytics
Key Innovations
1.Single Protein Molecule Flow Cell
The vast majority of protein analysis tools, such as affinity-based methods like an ELISA (Enzyme-Linked Immunosorbent Assay), typically measure proteins in bulk. This approach works well for measuring small numbers of proteins, however, it quickly becomes very challenging when measuring hundreds to thousands of proteins. Additionally, going through multiple intermediaries to assess a protein’s concentration (such as protein capture, secondary detection, calibration between fluorescent output and concentration) places limitations on the accuracy, sensitivity, dynamic range and reproducibility. Genomic studies are able to get around these limitations by amplifying DNA or RNA, but unfortunately, there is no equivalent approach for amplifying proteins available. Consequently, the limit of detection for most immunoassays has been bounded primarily by the signal-to-noise ratio provided by the instrument used to detect antibody-antigen binding and by non-specific binding, which in a 50uL sample could represent tens-of-thousands of molecules. Accordingly, the dynamic range of such platforms are typically about 1-order of magnitude, though this can be scaled through dilution at the upper end. 
Nautilus recognized early on that in order to achieve its goals for creating extreme protein detection sensitivity it would require measuring proteins whose frequency in a sample might vary from only a few, to hundreds of millions of molecules in a sample. In our view, it was clear that any bulk measurement technology would struggle to cover this immense dynamic range, and that a single protein molecule detection approach would be required to overcome a problem that has long been a barrier to major advancement in the field. Additionally, transitioning from bulk protein measurements to single protein molecule measurements fundamentally changes the nature of the protein quantification problem where the challenges of protein identification and quantification converge. If one is able to identify each protein molecule, quantification arises simply from counting those identifications, and furthermore, single protein molecule counters are by definition the most sensitive detection modalities available.
To break through these barriers, we have designed our Nautilus platform to measure billions of individual protein molecules at a time, in a massively parallel and efficient workflow. We refer to Nautilus’ framework for what we believe to be a fundamentally different approach to protein analysis as Protein Identification by Short-epitope Mapping (PrISM). Our internal testing has demonstrated that our hyper-dense single molecule protein nanoarray contains 10 billion landing pads. Our team has developed a process for manufacturing our nanoarray as the foundational component of our flow cell consumable. The flow cell itself is comprised of a nanometer-scale fabricated chip that holds the individual protein molecules in place on the surface in a landing pad, encapsulated by a fluidics channel that allows for reagents to flow across the surface. Our design includes the isolation of individual proteins in a protein library preparation by binding them to a much larger scaffold which has been created to hold exactly one protein molecule. 
These scaffolds can be reliably made to precise sizes, and the flow cell nanoarray surface can then be generated by well understood manufacturing processes to create surface features, which we call landing pads, that match the dimension of the scaffold. As each landing pad can only hold one scaffold, and each scaffold can only hold one protein molecule, the introduction of scaffold-protein complex onto the nanoarray surface generates a self-assembling, high-density single protein molecule array (as seen in the below illustration). The attachment between the scaffold and the nanoarray surface is extremely robust, enabling scaffolds to persist through extensive reagent washing across many cycles.
Nautilus Single Protein Molecule Flow Cell Designed to Capture One Individual Scaffold-Protein Complex per Landing Pad
As discussed above, our flow cell is designed with the capability to capture up to tens of billions of individual, intact protein molecules. The single protein molecule nature of the Nautilus platform is designed to enable extreme sensitivity, which we have observed in our internal testing as shown in the “Nautilus Platform Sensitivity” section below, and the sheer scale of proteins captured enables the measurement of proteins across an exceptionally wide dynamic range. Flow cells with loaded protein libraries can then be introduced into our proteome analysis system for the analysis and quantitation of the captured protein library. 
Nautilus Single Protein Molecule Flow Cell is Designed at Nanometer-Scale to Cover the Information Density Needed to Measure Approximately 95% of the Human Proteome
2.Our Proteome Analysis System: An Integrated Multi-cycle Optical and Fluidics Instrument
Typically, protein measurement approaches, like the ELISA described earlier, are designed to perform a single measurement of the proteins in a sample, after which the sample is either damaged, destroyed or discarded. However, if proteins captured in a sample can be repeatedly probed, it becomes possible to gain far more insight on the individual molecules. With our platform, each protein molecule has a unique coordinate address on the flow cell, and repeated probing enables deeper characterization of each individual molecule with each cycle, unlocking the ability to characterize proteoforms and ultimately decode the whole proteome.
Nautilus Platform Multi-Cycle Affinity Reagent Probing, Imaging, Washing, and Re-Probing
To achieve extreme sensitivity and scale, we have designed a novel instrument that integrates reagent fluidics with a sensitive high-resolution optical imaging system to cyclically measure all single protein molecules captured on the flow cell. Our affinity reagents are labeled with proprietary fluorescent labels that help improve both the signal-to-noise and speed of our assay chemistry. The instrument introduces labeled affinity reagents into our flow cell, allowing them to briefly incubate, then rinse off unbound molecules, and then rapidly images the entire surface. During the imaging process, a laser system is used to excite and illuminate the fluorescent labels. The high-resolution imaging components allow resolution sufficient to characterize each individual protein molecule, generating data as shown in the above illustration. 
Once an imaging pass is complete, the instrument then washes the flow cell, leaving the proteins fully immobilized, and rinses out the wash reagent before pursuing additional cycles. Samples may be multiplexed in a variety of ways to enable higher sample throughput and to reduce the cost per sample. A typical full scale proteome run will generate approximately 20 terabytes of data, which is then compressed to a digital binding matrix for downstream analysis by our cloud-based software-as-a-service, SaaS, analytics suite.
3.A Novel Class of Affinity Reagents for Efficient Whole Proteome Analysis
Our Nautilus platform technology is designed with fundamentally different principles of how to use and exploit the properties of affinity binding reagents compared to prior methods. Historically, affinity binding reagents have been qualified for use based on their specificity to a given protein target, and showing the ability to bind strongly to that specific target. In order to see and measure a single protein target, a researcher would require an affinity reagent of sufficient specificity to detect it. These high specificity affinity reagents are commonly used for bulk measurements, and are typically only used for one single bulk measurement event (or cycle) and then discarded.
By using these same high specificity reagents in our system, we believe it is possible to detect each specific protein target now at the single-molecule level, enabling digital quantitation. We further believe it is possible to expand this concept, and use our Nautilus platform with a wide variety of “off-the-shelf” affinity reagents that are highly specific to multiple individual protein targets. Also and of particular importance, is these off-the-shelf affinity reagents can often also target very specific sites on the protein itself, such as post-translational modification sites. Using reagents that target very specific locations and features of proteins will allow the Nautilus platform to detect and quantify the different patterns and varieties of post-translational modifications (i.e. the proteoforms).
In a highly innovative and counterintuitive way, our Nautilus platform has also been designed to exploit low specificity affinity reagents. Identifying the tens-of-thousands of different proteins in a proteome would require a prohibitively large 
number of traditional highly specific affinity reagents. We therefore explored the possibility of using affinity reagents that bind short, linear epitopes (e.g., target protein sequences of 3-4 amino acids each) with moderate specificity, such that each affinity reagent binds many proteins that contain the short linear epitope target, each a “multi-affinity reagent”. While the binding of a single multi-affinity reagent is not sufficient to identify a given protein, sequential binding events using a series of multi-affinity reagents can create enough information that it is sufficiently powerful to accurately identify an exceptionally broad number of proteins present in a sample. In this approach, each new affinity reagent that is introduced in a cycle of binding and imaging provides additional evidence and gradually narrows the list of possible protein identities. Hereafter, we refer to our proposed approach as Protein Identification by Short-epitope Mapping (PrISM). Our Nautilus platform technology is estimated to achieve the detection of the vast majority of proteins in the proteome using a combination of approximately 300 unique multi-affinity reagents.
Nautilus Platform Technology Protein Identification with Increasing Multi-Affinity Reagent
Source: A theoretical framework for proteome-scale single-molecule protein identification using multi-affinity protein binding reagents. Jarrett D. Egertson, Dan DiPasquo, Alana Killeen, Vadim Lobanov, Sujal Patel, Parag Mallick bioRxiv 2021.10.11.463967.
4.Machine Learning Protein Identification Software
Among the most unique aspects of our Nautilus platform is the integration of a proprietary machine learning-based protein identification analysis software engineered to work with the type of data our system generates. As discussed, more typical measurements for high specificity reagents can be used in our system to identify, and thereby quantify, each protein from a single binding and imaging step. These high specificity affinity reagents can provide a lot of information about a small number of proteins, and as such it would take an exceedingly large number of highly specific affinity reagents and therefor an exceedingly large number of cycles to measure every protein in the proteome. To enable broad protein identification on our system, we instead use our multi-affinity probes that can bind to hundreds or even thousands of individual proteins in a given cycle.
Our proprietary algorithm is thereby trained using experimental data from our probe development process that provides a baseline estimate of how likely each probe is to bind to each protein in a reference proteome database. As data is collected, a binding matrix is generated for each protein coordinate. For example, a given coordinate [2,1] may have bound probes during cycles [4, 11, 25, 26, 27, 65, and 201]. This data is then fed into our machine learning protein identification analysis to determine which protein is most compatible with the observed pattern of binding. The illustration below provides a view of our machine learning protein identification analysis at work by observing the confidence the algorithm has with respect to each protein as additional cycles of data are collected. On average, it takes roughly 15 cycles of multi-affinity probe biding events to uniquely identify a protein. Prior to 15 cycles, there is a lot of variability in which the protein is likely to be at a given spot, but then after 15 cycles, the algorithm locks in on a precise protein and becomes increasingly more confident in its identification. Further, with each additional cycle the other potential proteins become increasingly less likely.
Nautilus Platform Technology Can Identify a Protein by Analyzing Data from Multiple Cycles of Multi-Affinity Reagent Probing with High Probability
Source: Internal Data
The machine learning protein identification analysis is run for each of the 10 billion protein molecules captured on the flow cell in parallel to identify each protein molecule present. Following this, each identification is counted to produce a cumulative, absolute quantification. As the algorithm learns more and more about each multi-affinity probe’s binding characteristics, both within and across Nautilus platform data sets, it is able to adapt and update its confidence in each protein identification, essentially getting “smarter” over time. As a result, the machine learning protein identification analysis is able to re-analyze data collected in the past and continuously improve upon its ability to identify proteins within that data. 
Our Technology Workflow
From the earliest stages of developing the Nautilus platform, we set out to integrate the four key innovations (listed in the above section) into a single, cohesive proteomics workflow, creating an end-to-end solution designed for ease-of-use, speed, scale and performance. We believed that doing so could unlock the potential to democratize proteomics and make it possible for the broader scientific community to undertake a wider range of new, high-value scientific inquiries, thereby accelerating research and ultimately impacting healthcare and the development of precision medicine.
The Nautilus workflow is designed to consist of five major steps, beginning with sample preparation and concluding with the machine learning analytics that yields high-value proteomic data.
•Step 1 – Sample Preparation 
The Nautilus sample preparation process attaches a label to extracted proteins and then attaches them to a proprietary scaffold to isolate them individually, thereby creating a library of single protein molecules. This process was designed to be simple, robust, and rapid. Internal tests demonstrate that substantially all of the proteins are attached to the scaffold within two hours, creating the prepared protein library.
•Step 2 – Sample Deposition onto the Flow Cell
The protein library is then deposited onto the flow cell capable of holding up to 10 billion intact single protein molecules. The landing pads on the flow cell are matched to the size of the protein-attached scaffold, thus allowing only one protein to be deposited per site. This element of the process was specifically designed to enable massively parallel, rapid, single-molecule sampling of proteins, as shown in the flow cell occupancy figure below. 
•Step 3 – Integrated Imaging and Fluidics System using Multi-Cycle Affinity Reagents
Once the proteins are deposited onto the flow cell, it is then loaded into the proteome analysis system to measure each individual molecule in a multi-cycle system run. The process entails introducing affinity reagents into the flow cell, rinsing out the unbound fraction, imaging the surface area, and then stripping and washing the affinity reagent away. This step is then repeated sequentially to collect data on the desired number of cycles.
•Step 4 – Processing of Digitalized Proteomic Data
After the proteins on the flow cell have been iteratively imaged over the determined number of cycles, the resulting raw images are converted into a coordinate map with corresponding illumination signals indicating positive affinity reagent binding events, effectively digitizing up to approximately 20 terabytes of raw image analyzed proteomic data.
•Step 5 – Machine Learning Analytics - Decoding, Protein Identification, and Quantity
In the final step of the workflow, the digital proteomic data is analyzed by our cloud-based machine learning protein identification analysis software. The data is converted to protein identities during this analysis, evaluating the characteristics of each affinity reagent binding event at each location to determine protein identity and quantity.
Nautilus Platform Technology Performance
Simple and Robust Sample Handling
Nautilus’ straightforward sample protein library preparation is designed to convert protein samples into a format optimized for single-molecule deposition on our flow cell. The process has been designed to be accessible to virtually any life sciences researcher. In addition, our forthcoming sample protein library preparation instrument is expected to further simplify the workflow by introducing automation. Also, unlike existing shotgun proteomics methods, no sample protein digestion is required in our method which in turn makes the workflow very simple. The result is a process that is expected to effectively prepare a sample into a library ready to load on the flow cell in approximately 2 hours.
A key feature of our Nautilus platform is the large scale (up to billions) of protein molecules that we believe can be measured massively in parallel on our single-molecule flow cell. An analysis of nearly 1,000 flow cells showed typical sample loading of single protein libraries yielded near complete flow cell occupancy, which demonstrates the speed and efficiency of our sample handling process. 
Flow Cell Loading Demonstrates Approximately 97% of Flow Cell is Occupied with Protein Library
Nautilus Platform Stability in Multi-Cycle Experiments
We believe we have designed a technology with direct applicability in research use settings as well as having the potential to translate discoveries into healthcare practice. A critical aspect of any molecular detection technology with translational and clinical potential is robustness and reproducibility. To understand how stable our measurement process was, we tested the durability of our flow cell with a loaded protein library to ensure that proteins remained present on the surface over multiple cycles in a proteome analysis system run. In our studies evaluating stability over numerous cycles, we observed substantially less than 1% of proteins were lost from the flow cell as seen on the panel below on the left. As shown on the right figure, to examine both the effectiveness of our wash buffer and the ability of proteins to be probed after being washed, we first examined the detection ability of the protein on a first cycle (blue). We next demonstrated that our wash buffer successfully eliminated remaining signal (yellow). Last, we demonstrated that after extended exposure to washing, and rinsing, that the protein detection remained nearly identical to the initial measurement (red). These results suggest that our wash conditions are highly effective and that our process of reagent cycling does not significantly damage the protein and thereby interfere with the probability of its measurement accuracy. 
Protein Library Remains Bound to Flow Cell During Repetitive Probe Binding and Wash Cycles
Nautilus Platform Sensitivity 
Our Nautilus platform is designed both to be extremely sensitive (by virtue of being a single protein molecule platform) and to have an extremely wide dynamic range of detection (by virtue of measuring a very large number of molecules). In single protein molecule assays, dynamic range is defined by the total number of molecules measured. Consequently, a platform measuring a million molecules will have a smaller dynamic range than a platform measuring 10-million molecules. On our Nautilus platform, we project we will be able to reach sensitivity down to 1 molecule out of 10 billion. The figure below shows a limit of detection experiment performed on the Nautilus platform, approaching attomolar sensitivity (1 out of 1016). We are also able to use this sensitivity in flexible way, for example we can perform an extremely deep analysis of a single protein library sample across all lanes of a flow cell, or we can perform a multiplexed analysis by processing a batch of samples together (each sample protein library individually barcoded) during one proteome analysis system run.
Extreme Sensitivity Quantified by 10-16 LOD (Limit of Detection) 
Mapping Proteoforms
We believe there are likely millions of different proteoforms that define cellular activity, cellular localization and biochemical function. With peptide-centric approaches (detecting only small pieces of proteins), such as “shotgun” mass spectrometry, it is simply impossible to differentiate proteoforms. Using phosphorylation as an example for a post-translational modification of a protein, consider the case of two samples as shown in the figure below. On the left, one protein sample contains a single protein molecule with a triple phosphorylation (red) and two unmodified proteins versus a second sample on the right, in which each protein molecule contains one phosphorylation each at a single different site. These two samples would likely appear identical to one another in a shotgun mass-spectrometry analysis.
The Nautilus Platform Detection of Proteoform Patterns 
On our Nautilus platform, we are able to use existing commercially available affinity reagents to perform detailed mapping of proteoform patterns at the single protein molecule level. We do this by measuring individual proteins at each specific post-translational modification site over multiple cycles, each cycle targeting a different specific site or feature of the protein. For example in the diagram below, during the first cycle we use an EGFR affinity reagent to identify all of the EGFR proteins present on the flow cell. Then over the next 4 cycles we detect each EGFR molecule again, only now with a slightly different affinity reagent that targets each different location of a phosphorylation modification on the EGFR protein. Looking at this data together over 5 cycles, our technology is potentially able to distinguish up to 16 different proteoforms (in this case, different phosphorylated patterns) of the same EGFR protein and the quantity of each proteoform in a sample.
We demonstrated this principle of proteoform detection by looking at three samples on our Nautilus platform. These three samples were designed from purified protein to detect different proteoforms of the same basic protein. The first sample was primarily a protein in Proteoform 1 form. The second sample was primarily a protein in a mix of Proteoform 1 and Proteoform 2 forms. The third sample was primarily a protein in Proteoform 2 form. As shown in the figure below, the Nautilus platform is not only able to both differentiate between these forms, but is also able to do so quantitatively and therefore determine how much of each proteoform is in each sample.
Nautilus Platform Proteoform Pattern Detection and Quantitation
Nautilus Platform Development Plan Key Areas of Focus 
In order to achieve our goal of broad commercialization by the end of 2023 or beginning of 2024, we plan to advance the development of our Nautilus platform across all components including chemistries, reagents, consumables, instrumentation and analysis software. The prototype of our proteome analysis system has generated all of our internal data to date, and we are continuing the development process to optimize, improve upon, and validate the final designs, formulations, protocols, manufacturing processes, and software code comprising our Nautilus platform.
Our development plan will build upon the foundational achievements our prototype technology has made in several key areas, with the goal of ultimately allowing us to fully realize the potential of our technology. We plan to focus on the continued improvement of our flow cell designs. Having initially demonstrated that prototype versions of our flow cell can functionally achieve 10 billion discrete single protein molecule landing pads, we plan to further optimize the landing pad spacing, density, manufacturing process and chemistries of the first commercially available flow cells. We also intend to focus on the completion of the final engineering design of our proteome analysis system, where we plan to complete the development of manufacturing processes to integrate and test all completed sub-systems including the high-speed optical subsystem, fluorophore excitation laser, and micro-fluidics system in combination with our flow cell. We also plan to continue expanding the number of affinity binding reagents and chemistries that can be used within our proteome analysis system for both broad scale proteomics quantification and target quantification of proteoforms at the single molecule level. Our aim is to create a broad portfolio of affinity binding reagents through in-house reagent development efforts and through strategic partnerships where we qualify already developed reagents for compatibility with our technology. Lastly, we intend to continue the development of our analysis software, where we expect improvements to our algorithms and analysis that will help with the speed, accuracy, and reliability of our commercial proteome analysis system performance.
Assuming the completion of our development across these focal areas on our currently anticipated timeline, as well as additional related development activities, we believe we will be in position to achieve our goal of broad commercialization by the end of 2023 or beginning of 2024.
APPLICATIONS OF OUR TECHNOLOGY
The Nautilus platform technology is an open platform that is designed to leverage a wide variety of reagents to read and quantify the proteome and proteoforms
We believe that our Nautilus platform technology is designed to represent one of the first truly novel technologies for the detection and quantitation of proteins and proteoforms by leveraging the creation of our single protein molecule flow cell in combination with a broad range of affinity binding reagents. By design, our Nautilus platform technology is open to the use of virtually any affinity binding reagent, where each reagent can be efficiently chemically labeled and used in our multi-cycle process to identify and quantify a protein library. We further believe one of the inherent strengths of the open design of our 
Nautilus platform is the ability to use reagents across a range of different binding profiles to create unique applications that unlock different types of important biological information.
On one end of the spectrum (above left), our technology is designed to harness the power of low specificity multi-affinity binding reagents that will potentially allow us to detect substantially all of the proteome. On the other end of the spectrum (above right), we believe we can apply high specificity affinity binding reagents that detect and quantify individual target proteins of interest, and the post-translational modifications of these target proteins to detect and quantify the various proteoforms that may exist. We believe it is this inherent flexibility of reagent applications on our Nautilus platform that will enable a broad suite of uses across research, discovery, translational and clinical applications. Because of this inherent flexibility, we also believe our Nautilus platform will spark the creation of new and unforeseen applications, in a similar market expansion and innovation trend that was experienced in the years following the launch of open and flexible NGS platform technologies. 
The open nature of the Nautilus platform creates the opportunity to partner with third-parties on the development and supply of affinity reagents. To that end, in the fourth quarter of 2021, we initiated a strategic partnership with Abcam, a world leader in the design and production of assay kits, reagents, and antibodies. This type of development and supply agreement is expected to provide us with antibodies additive to the affinity reagents we are creating internally and serves to highlight the flexible nature of our technology.
Basic Research and Discovery Applications
The Discovery Potential of Our Nautilus Platform
One of the long-standing challenges to accelerating the discovery and understanding of protein biological function has been the overwhelming dynamic range of proteins present in a cell or a biospecimen. We believe that a sensitivity of detecting 1 protein molecule in as little as 1,000 cells will be required to identify the exceptionally rare but biologically significant proteins in a sample. Our Nautilus platform is designed with this extreme sensitivity in mind, which we believe makes it ideally suited for capturing and cataloging the variation of the proteome in a comprehensive way, both in human and non-human species. 
Further, we believe speed, scale, and single protein molecule data quality will be required to enable research projects with aims to create new species-specific, tissue-specific, or disease-specific reference datasets that have the potential to accelerate discovery across academic and industry research communities. We believe our customers could embrace our Nautilus platform for these applications broadly. Comparatively, during the initial market adoption of NGS, as the instrumentation and methods improved in speed and data production scale, projects increased dramatically in size. Sample cohorts grew from dozens of samples to hundreds, and then to thousands in an effort to use the speed and data production capacity to improve the statistical power required to make new discoveries. We believe our Nautilus platform technology could experience a similar trajectory of utilization for research and discovery applications, making very large sample size studies that were not feasible using prior proteomic detection methods now practical for our customers to implement. 
A deeper level of detail and molecular complexity also clearly exists beyond the estimated 20,000 proteins in the human proteome, and we expect our customers to utilize proteoform specific reagents for the profiling, mapping, and characterization of post-translational modification patterns on proteins of interest. It is estimated there are as many as 6,000,000 different 
proteoforms produced through protein modification pathways that hold critical biological and contextual information on the function and purpose of the proteins in our cells. We believe our customers could show strong interest in this important field of research given the lack of technologies and tools in existence today capable of mapping multiple features on a single protein in one analysis workflow. We believe discovery focused proteoform specific reagents could be used in combination with our multi-affinity broad protein detection method to enhance the output of our analyses. 
Multi-Omic Systems Biology and Proteogenomics
We believe the creation of matched DNA, RNA and protein data sets for integrated multi-omic (DNA, RNA and protein) analyses will enable a more complete understanding of the path of information transfer from gene, to transcript, to protein. It is estimated that at most only 40% of protein expression can be predicted by gene expression data. Integrated multi-omic data sets are expected to have far greater potential for better understanding this discordance, its biological origin, and ultimately its impact on cell function with deeper and more complete proteomic data. We expect the creation of workflows with matched NGS and proteomic data will become standard practice in the community, further driving the utility and value of our Nautilus platform technology.
Proteogenomics is an emerging area of research, with the goal of identifying brand new proteins or proteoforms not currently captured in the protein reference sequence. In proteogenomics, individual protein sequence databases are generated using matched transcriptomic and genomic data to aid in the identification of novel peptides and proteins detected but not yet mapped within the reference databases of known proteins. In this area of research, the integration of genomics and gene expression data enhances the predictive capability to determine what new proteins are present in a sample, and further brings functional context to genomic information and gene expression patterns. Our Nautilus platform represents an entirely new single protein molecule data source for proteogenomics, which we believe could contribute significantly to the field by increasing the scale of proteomic data accessible for these analyses, and ultimately increasing the discovery potential of the integrated dataset. Given the current level of access to genomic and transcriptomic information enabled by NGS, we believe the research community could rapidly integrate data from our Nautilus platform technology into these studies to leverage matched genomic and proteomic data.
Translational Research and Discovery Applications
Biomarker Discovery 
It has been published that approximately 95% of FDA-approved drug targets are proteins. Currently, FDA-approved drugs are targeting 812 separate human proteins and there are 4,514 genes in the UniProt database that have experimental evidence for being involved in disease. We believe that the drug development and diagnostic industries have suffered from an inability to access the low frequency and rare proteins present in biological samples due to the tremendous dynamic range present across proteins in a specimen. As already described, we believe that our Nautilus platform technology is designed with the scale to adequately overcome the dynamic range problem in proteomics, and provide researchers with access to the rare, but biologically important protein detection where biomarkers are believed to exist. We believe our Nautilus platform’s sensitivity targeting the detection of events as rare as 1 protein molecule in 1,000 cells will be critically important and may unlock the potential for many new biomarkers to accelerate the development of precision medicine diagnostics and therapeutics.
Proteoform Patterns as Biomarkers and Mechanism of Action Studies 
We believe the study of proteoform patterns, proteoform frequency, and proteoform diversity of critically important drug targets will be a widely used application of our Nautilus platform. Which drugs work on specific protein drug targets is not just a result of the total number of post-translational modifications, but instead by how combinations of specific post-translational modification are operating together. Our technology is designed to enable the research community to see these proteoform patterns, and to measure their relationship to one another. Every disease is the result of a dysregulation of molecular functions that create biological consequences compared to normal healthy function. Given the inability to detect proteoform patterns today, we believe this will become an essential application of our technology used to investigate important drug targets and molecular disease pathways. We believe this application has the potential to advance precision medicine by making an entire layer of molecular complexity and information available to researchers for the first time.
Longitudinal Monitoring of Proteome Dynamics 
The study of proteome composition, protein and proteoform frequency, patterns, and variations over time represents an opportunity to survey and understand the biological changes resulting from environmental factors that influence our health and wellness. Individual or small panel protein surveillance tools have existed in the healthcare market for decades using traditional assay methods across a range of biospecimen, all of which have the same inherent limitations as those in the research space. Also, cell-free nucleic acid methods have emerged recently as amongst the first molecular surveillance tools in oncology for the 
emergence of disease progression post treatment or surgery, and may also prove to enable the detection of disease at earlier stages in some cancers where cell-free nucleic acids are present at higher levels. However, the same fundamental challenges exist in this setting. Nucleic acids are still only a proxy for measuring the biological consequences of the functional proteins, and further the sensitivity needed to find early-onset molecular features of disease before it presents clinically is incredibly high. We believe the routine surveillance of proteins at sufficient breadth and depth to capture even the exceptionally low-frequency changes will be a key area of interest in the future. This application has implications across not only oncology, but across virtually any human disease where the molecular underpinnings driving that disease may one day be revealed and then tracked to identify that disease earlier, measure the response to treatments, and create a comprehensive and dynamic view of our overall molecular health.
Diagnostics, Clinical Research and Drug Development Applications
Transitioning from Discovery into Clinical Application
We believe one of the largest and most impactful applications for our technology in the future will be the development of diagnostics that leverage the sensitivity, speed, stability, and ease of use we are designing our system to achieve. Significant technical and practical barriers have existed with prior high-throughput proteomic technologies preventing them from accessing the clinic. Despite advances in sample preparation methods, we believe the detection of enriched and modified protein samples by mass spectrometry will continue to experience challenges in the effort to transition to the clinic. We believe our novel protein detection method embodies the performance characteristics and design criteria that will be desirable for clinical applications. We further believe there will be opportunities to identify and develop content for proteomic clinical diagnostic tools as a result of the more direct nature of measuring the individual proteins at the source of biological function, as opposed to inferring biological function from genomic or gene expression measurements.
We also believe there will be an opportunity to leverage the proteoform pattern detection methods established in a translational research setting into the development of clinical tests in the future. We expect that once our technology is validated in a translational research setting for the identification of proteoform patterns which are themselves biomarkers of disease, we could potentially be in the position of being the only technology capable of physically detecting such patterns. We believe this presents an opportunity to use our Nautilus platform to continue to advance these applications and methods of proteoform pattern biomarker detection from discovery all the way through to future diagnostic using our technology. As we work to build evidence with our customers and partners on the utility of new proteoform patterns as translational and clinical biomarkers, we believe such applications of our Nautilus platform could have a profound impact on precision medicine.
Precision Medicine Development & Clinical Trial Support 
We believe there is tremendous demand for broad scale proteomic data across the continuum of preclinical and clinical drug development. Starting at the earliest stages of therapeutic asset development, the ability to strategically inform and prioritize experimental compounds with deep proteomic data will provide a much more comprehensive view of cellular responses and resistance mechanisms. This data may also create a new perspective on how to modify experimental therapies to interact with molecular pathways in much more specific and intentional ways. We believe these types of applications present a very compelling use-case for our Nautilus platform.
We first expect adoption of our Nautilus platform could occur in the preclinical and clinical retrospective settings, where we believe single-molecule proteomic and proteoform composition and frequency will become essential tools in building a more complete picture of how experimental medicines are interacting in complex molecular pathways. Each individual tissue type offers its own unique profile of expressed proteins and functions, where advances in proteomic data breadth and depth may elucidate how and where a compound is interacting within these different cell types. We also believe this type of comprehensive proteomic analysis could become an important tool for improving our understanding of drug toxicities, metabolism and distribution. For this application, our technology has the potential to substantially improve visibility to the entire landscape of drug-target interactions, and consequently may help to improve the probability of creating strong therapeutic responses while minimizing detrimental or off-target effects. As these new insights become available, we further believe our customers may engage in very large-scale studies to catalog the frequency of target proteins and proteomic patterns across large and diverse biobanks that represent the intent to treat populations of interest, which will help inform and prioritize the development strategy and the potential impact of their experimental therapy pipelines.
We believe that as these advances in the application of large-scale proteomic data are realized in preclinical and retrospective settings, a natural transition will occur where our customers and partners will seek to apply their learnings in prospective settings. In the prospective clinical development environment, we believe the same design features which make our Nautilus platform desirable in a research setting can be fully realized. Prior proteomic profiling technologies have struggled to make an impact in prospective clinical settings due to a lack of run-to-run data reproducibility, slow turn-around-time, and overall complexity of practical implementation. We believe our Nautilus platform design is ideally suited for the quality, 
stability, and speed required to fully realize the value of accessing deep proteomic profiling data to identify biomarkers that stratify patients for clinical trials and improve drug development.
OUR PRODUCTS
Overview
Our primary business model is anticipated to be focused on the commercialization of our Nautilus platform through the sale of instrumentation, consumables, and software. Our proteome analysis system is our detection instrument at the center of our product suite, supported by reagent consumables for the preparation and analysis of proteins, and followed by sophisticated machine learning software architecture for the analysis of our data in the cloud.
Proteome Analysis System & Reagent Kits
Our proteome analysis system is a high-resolution optical imaging sub-system coupled with an integrated fluidics sub-system in order to process multi-cycle labeled affinity reagent binding and imaging runs. System run reagent kits are comprised of two main components: the flow cell(s), and the affinity binding reagents used to perform multi-cycle analysis runs.
Our initial flow cell design includes 4 physically separated and independent fluid channels, or “lanes”, such that a customer can introduce a unique biological sample in to each lane for multi-cycle analysis. Our proteome analysis system is designed to hold and concurrently analyze up to three flow cells in a single system run, for a total of 12 lanes. Additional sample throughput may also be achieved by the use of a molecular barcode in our reagent kits that will enable the multiplexing of more than one barcoded sample library together within a single lane for analysis. Our high-throughput multiplexed reagent kits are expected to support up to 24 samples per run, and may be further scaled in the future.
Affinity binding reagents will also be included within each system run reagent kit. Reagent kits will be offered in configurations that cover a catalog of proteomic content desired by our customers by supplying different combinations of reagents together within a given kit. We intend to supply a standardized set of affinity binding reagents for the broad-scale detection of proteins, or “proteome kits”, as well as protein-specific or proteoform-specific reagent content sets, or “targeted proteoform kits”, focused on high interest areas of disease research. Additionally, custom affinity reagent labeling kits are expected to be supplied to enable customers to label their own in-house developed affinity reagents to be compatible with Nautilus chemistry for use on the system.
Sample Preparation Kits 
Our proprietary sample preparation kits are expected to be intended for the isolation and library preparation of proteins from a variety of input materials including cell cultures, tissues and biospecimen. The library preparation includes an automatable workflow consisting of chemically labeling target proteins and attaching them to a scaffold used to deposit proteins on our flow cell. Given the breadth and depth of data output capability planned for our proteome analysis system, it is not expected that additional protein sample enrichment, enhancement or pre-treatments of samples will be required for processing, but we do intend to be compatible with such input materials. We also expect our customers and partners may intend to design their own custom process to target specific proteins prior to creating a library with them, and we intend to ensure our kits will be compatible with pre-treated or enriched protein samples. Our protein library preparation process is designed to be simple, efficient, and robust, all features which are expected to allow for easy automated processing for high throughput applications.
Software & Analysis
Our machine learning protein identification analysis software suite also is expected to be utilized as the secondary analysis engine to decode the proteome analysis system raw data. Our software is expected to be a SaaS based service, utilizing Nautilus’ machine learning computational algorithms required to identify and quantify the proteins or proteoforms present on the system run. Our software is a learning and evolving system, which we are designing to improve in accuracy over time as the protein feature profiles are refined and trained across a growing database and our software has demonstrated this potential ability in our internal tests. We expect our software enhancements in performance will also be accessible to customers who wish to re-analyze prior run data with later versions to deliver new insight and discovery value.
SALES & MARKETING
Commercial Strategy
The primary business model we intend to implement is to directly commercialize our entire end-to-end Nautilus platform technology solution through the sale and installation of our proteome analysis system at customer sites; the ongoing sale of consumables covering a broad suite of applications run on our system; a SaaS analytics and insights software subscription to 
capture long term value created by our machine learning-based analysis enhancements; and a service warranty plan to maintain our install base and support our customers in the field. We believe a comprehensive solution could offer a compelling value proposition across multiple market segments due to the substantial enhancements it will create in speed and scale of data creation, single protein molecule quantitation, sensitivity, and reproducibility. 
We initially intend to target customers with a history of strong performance in proteomic research, and a substantial annual research budget allocation for proteomics technologies and proteomic data. We expect many of our customers will already have high complexity molecular analysis laboratories which include high throughput proteomic or genomic analysis capabilities on site. These customers represent a segment of the greater than 16,000 system install base of mass spectrometry detection systems already in use, many of which are dedicated to proteomic analyses. Our early customers are expected to include large pharma and biotech research groups, sophisticated proteomic translational research laboratories in academia, and large-scale commercial and academic multi-omics research laboratories. As our Nautilus platform is introduced into these customer segments, we further intend to expand our commercialization into clinical settings, where our target customers are expected to include pharma and biotech clinical development groups, contract research organizations, and ultimately, diagnostic laboratories. 
Our proteome analysis system is expected to be priced in-line with mass spectrometry peptide detection equipment, or high-throughput NGS equipment, making the capital expense for our system within the budget for our initial customers. Our consumables are expected be priced at a level that provides comparable market value for full proteome analysis. The use of multiplexed run configurations will continue to grow over time, which we believe will help to reduce our costs and the price-per-sample of our reagent kits such that we are able to support customers with very high-throughput applications of our systems. We expect these high-throughput run configurations and economics to accelerate the initiation of large-scale proteomics and multi-omics research projects, and also to be much more compatible with centralized core lab facility operations with requirements for proteomic data generation that can support an entire organization or user base.
Because we believe our unique approach to protein and proteoform detection is a significant deviation from any prior method, we believe it is critical to provide the market with peer reviewed publications describing our technology and its performance capabilities, and to demonstrate its ability to deliver new biological insight. Our publication strategy is a key component of our overall go-to-market plan, and we expect to spend considerable time and resources building these fundamental proof-sources to accelerate adoption of our proteome analysis system. We further believe that once our proteome analysis system is launched, a key performance indicator of our success will be the rate of new publications generated using our technology. We intend to track this closely, and we expect to invest both internally and externally to accelerate the pace of new research and publications leveraging our Nautilus platform pre- and post- proteome analysis system launch.
Go-To-Market Strategy
We expect our proteome analysis system technology will be highly disruptive to the current proteomics technology and market landscape, and as a result, we have designed our go-to-market plan with a similar strategy to the highly successful NGS platform technology introduction and commercialization in genomics. We also believe that engaging with the market early is a critically important activity in building confidence and awareness of our technology and its capabilities. 
Our planned go-to-market strategy is organized into 3 phases:
1)Collaborations & Partnerships 
2)Early Access Program 
3)Proteome Analysis System Launch & Commercial Scale Up
We have mapped the phases of our go-to-market strategy against specific technology development milestones which we believe will allow us to build the value proposition of our technology early, and to grow it in conjunction with our Nautilus platform enhancements over time. Our strategy to utilize our Nautilus platform early in its formal development cycle through partnerships is an important component, and in part can be attributed to the inherent flexibility we have to employ commercially available reagents for targeted applications of single-molecule proteomics that drive new and significant discovery value. Further, as we advance from low-cycle targeted applications towards longer runs with increasing data output, we believe each of the milestones on our development plan are potentially new and unprecedented advancements we can leverage to build commercial momentum.
Aligning Go-to-Market Strategy with Research and Development Milestones
Collaborations & Partnerships 
We believe that directly engaging the market early, well before system launch, has the potential to be a very important differentiator to raise awareness of our novel Nautilus platform as it matures throughout the formal development process, and to build credibility as we educate the community on our scientific approach through the value of our data. We believe the most effective way to engage our future customers now is through partnerships and collaborations, with the primary purpose of driving new and meaningful biological insights while demonstrating our technology’s performance, unique characteristics, and capabilities. We have launched a formal partnering program with the goal of establishing multiple research collaborations generating data and publications in high impact research areas. We also believe we can use these collaborations to improve the performance characteristics of our technology during development, and we can shape the system and run parameters to more precisely meet our customer’s needs. We intend to target projects with these engagements that will help to define and validate our product applications, which we expect will further aid in the rapid adoption of such applications once directly commercialized as products.
Early Access Program
Following the important Collaboration and Partnership work necessary to lay a foundation of publications describing our technology and the initial product applications, we believe we will have a body of scientific evidence sufficient to start building demand for our technology and the single-molecule proteomic data it generates. We then intend to initiate our pre-sales activities, which include the launch of an Early Access Program comprised of a service offering that will generate data on customer biological samples using our prototype systems run by Nautilus staff in our facilities. Using this Early Access Program, we intend to begin building a pipeline of customer engagements, supporting their evaluations of our technology through proof of concept and pilot studies, and giving them access to our data to begin establishing interest in our proteome analysis system leading up to launch. 
We further intend to build on the momentum of our Early Access Program by expanding it to include a small group of target customers for the sales and subsequent testing of our first generation proteome analysis system on site at their facilities. Our goal in the planned proteome analysis system Early Access Program is to establish this influential group of customers as reference sites ahead of our broader commercial launch, and to integrate the learnings from our system performance outside of our own laboratories to improve the performance and robustness of our system and process design. 
Proteome Analysis System Launch and Commercial Scale Up
At full commercial proteome analysis system launch, we expect to continue offering our Proteomic Data Early Access Program, and to maintain the laboratory services to continue supporting POC and pilot projects for an extended period of time 
to continue building our sales funnel. Our proteome analysis system launch is expected to be coupled with a substantial scale up of our commercial sales and marketing workforce. We intend to employ a “land and expand” sales model to promote high value cutting edge technology adoption, where we will first establish a presence in key accounts across our customer demographics, then work to broaden and expand our value and contributions across those key account organizations while concurrently growing our customer base through an increasing salesforce. We expect to commercialize directly in the United States, and in the future to expand commercial operations to the Asia Pacific and European regions. Following our initial proteome analysis system commercial launch, we expect future system upgrades and enhancements periodically over time that will further drive discovery potential and our business with each incremental advancement.
Our planned commercialization strategy and technology are designed to offer a highly differentiated and defensible position in the market we intend to capitalize on. We believe we will have significant competitive advantages if we are able to execute on the following opportunities:
•Being first to market with a novel protein and proteoform detection platform; 
•Demonstrating the ability to unlock new sources of primary biological information with proteoform mapping and rare protein detection;
•Providing immense data production capacity, driving discovery by enabling large scale studies and building our database to become a strategic asset;
•Implementing a proven commercial model with an efficient direct salesforce; and 
•Expanding our impact into clinical applications, precision medicine and diagnostics.
Partnerships
In December of 2020, we signed a research collaboration agreement with Genentech to engage in a pilot study using our technology. This partnership is consistent with our objectives in Phase I of our commercial go-to-market strategy to build external collaborations and relationships that produce data and publications based on the application of our Nautilus platform technology to deliver a meaningful biological insight. We are collaborating with Genentech using our proteome analysis system to analyze and map the proteoform landscape of a Genentech protein target of interest. We aim to submit results for publication in early 2022.
In October 2021, we entered into a research collaboration agreement with Amgen in which the Nautilus platform will be used across a number of projects to investigate proteins and proteoforms of interest to the Company. Also in October 2021, we signed a research agreement with The University of Texas MD Anderson Cancer Center. The Nautilus platform will be applied in measuring the quantity and patterns of post-translational modifications on specific oncology protein targets of interest across different settings, such as pre- and post treatment.
Commercial Organization
We plan to build out a world-class commercial organization, focused on delivering value and support through every stage of the sales cycle. Our company is driven by the advancement of science and the improvement of human health, and we anticipate our commercial organization to be scientifically oriented to align with the goals and objectives of our customers. We believe strongly in building an exceptional support infrastructure, which we believe will be particularly important for our customers given the scale and novelty of data we anticipate our systems will provide. We aim to build long-term loyalty with our customers by enhancing their individual research programs, enabling their successes, and driving growth within their organizations through their successful use of our technologies. 
MANUFACTURING AND SUPPLY
Reagent and Flow Cell Consumables
We have designed and sourced our consumables primarily from third-party suppliers. While some of these components are sourced from a single supplier, we have qualified second sources for several of our critical reagents. We currently source base nanoarray chips and flow cell components, sample preparation and assay reagents. We believe that our suppliers have sufficient capacity to meet our near-term development needs through to commercialization. We believe it may be advantageous to have multiple sources for our consumable components and reagents in the future, to help reduce the risk of production delays or quality issues that may cause a disruption to our development timelines or pre-commercial activities. For further discussion of the risks relating to our third-party suppliers, see the section titled “Risk Factors— Risks Related to our Business.”
Instrumentation
Our proteome analysis system instrumentation automates the Nautilus assay chemistry concurrent with rapid optical imaging of the flow cell. The current system is an early-stage design, used for optimization of the function and design of each component. We currently source components for our systems from external manufacturers and assemble them in-house at our San Carlos, CA facility. Once development is completed, we will determine the most appropriate path for high volume production. This may consist of a process developed by contract manufacturing of major system components with final assembly and testing in-house, or fully outsourced production, or some combination of both.
COMPETITION
The life sciences market is highly competitive. There are other companies, both established and early-stage, that have indicated that they are designing, manufacturing and marketing products for, among other things, multiplexed or high-throughput proteomic analysis. Nautilus currently competes with technology and diagnostic companies that supply components, products, and services to customers engaged in proteomics analysis. These companies include Agilent Technologies; Becton, Dickinson and Company; Bruker Corporation; Danaher; Luminex; Olink Proteomics; Quanterix; SomaLogic; Quantum-Si; and Thermo Fisher Scientific. Nautilus also competes with a number of emerging companies that are developing proteomic products and solutions. Some of these companies may be further along in their commercial and operating plans than we are, including actively commercializing products and growing established marketing and sales forces. Other competitors are earlier than us, and in the process of developing their technologies for the life sciences market which may lead to products that rival or replace our products. 
However, we believe we are substantially differentiated from our competitors for many reasons, including our novel approach to high throughput and massively parallel proteomic technology, the unique and proprietary nature of our technologies, the novel detail of protein modification mapping our platform can achieve, our rigorous product development processes and quality of science, our multidisciplinary teams, and our access to an immediate growing market with opportunities to expand into adjacent translational and clinical markets. We believe our customers will favor our products and company because of these differentiators.
GOVERNMENT REGULATION
The development, testing, manufacturing, marketing, post-market surveillance, distribution, advertising and labeling of certain of medical devices are subject to regulation in the United States by the Center for Devices and Radiological Health of the U.S. Food and Drug Administration (FDA) under the Federal Food, Drug, and Cosmetic Act (FDC Act) and comparable state and international agencies. FDA defines a medical device as an instrument, apparatus, implement, machine, contrivance, implant, in vitro reagent or other similar or related article, including any component part or accessory, which is (i) intended for use in the diagnosis of disease or other conditions, or in the cure, mitigation, treatment, or prevention of disease, in man or other animals, or (ii) intended to affect the structure or any function of the body of man or other animals and which does not achieve any of its primary intended purposes through chemical action within or on the body of man or other animals and which is not dependent upon being metabolized for the achievement of any of its primary intended purposes. Medical devices to be commercially distributed in the United States must receive from the FDA either clearance of a premarket notification, known as 510(k), or premarket approval pursuant to the FDC Act prior to marketing, unless subject to an exemption. 
We intend to label and sell our products for research purposes only (RUO) and expect to sell them to academic institutions, life sciences and research laboratories that conduct research, and biopharmaceutical and biotechnology companies for non-diagnostic and non-clinical purposes. Our products are not intended or promoted for use in clinical practice in the diagnosis of disease or other conditions, and they are labeled for research use only, not for use in diagnostic procedures. Accordingly, we believe our products, as we intend to market them, are not subject to regulation by FDA. Rather, while FDA regulations require that research use only products be labeled with – “For Research Use Only. Not for use in diagnostic procedures.” – the regulations do not subject such products to the FDA’s jurisdiction or the broader pre- and post-market controls for medical devices. 
In November 2013, the FDA issued a final guidance on products labeled RUO, which, among other things, reaffirmed that a company may not make any clinical or diagnostic claims about an RUO product, stating that merely including a labeling statement that the product is for research purposes only will not necessarily render the device exempt from the FDA’s clearance, approval, or other regulatory requirements if the totality of circumstances surrounding the distribution of the product indicates that the manufacturer knows its product is being used by customers for diagnostic uses or the manufacturer intends such a use. These circumstances may include, among other things, written or verbal marketing claims regarding a product’s performance in clinical diagnostic applications and a manufacturer’s provision of technical support for such activities. If FDA were to determine, based on the totality of circumstances, that our products labeled and marketed for RUO are intended for diagnostic purposes, they would be considered medical devices that will require clearance or approval prior to 
commercialization. Further, sales of devices for diagnostic purposes may subject us to additional healthcare regulation. We continue to monitor the changing legal and regulatory landscape to ensure our compliance with any applicable rules, laws and regulations.
In the future, certain of our products or related applications could become subject to regulation as medical devices by the FDA. If we wish to label and expand product lines to address the diagnosis of disease, regulation by governmental authorities in the United States and other countries will become an increasingly significant factor in development, testing, production, and marketing. Products that we may develop in the molecular diagnostic markets, depending on their intended use, may be regulated as medical devices or in vitro diagnostic products (IVDs) by the FDA and comparable agencies in other countries. In the U.S., if we market our products for use in performing clinical diagnostics, such products would be subject to regulation by the FDA under pre-market and post-market control as medical devices, unless an exemption applies, we would be required to obtain either prior 510(k) clearance or prior premarket approval from the FDA before commercializing the product. 
The FDA classifies medical devices into one of three classes. Devices deemed to pose lower risk to the patient are placed in either class I or II, which, unless an exemption applies, requires the manufacturer to submit a pre-market notification requesting FDA clearance for commercial distribution pursuant to Section 510(k) of the FDC Act. This process, known as 510(k) clearance, requires that the manufacturer demonstrate that the device is substantially equivalent to a previously cleared and legally marketed 510(k) device or a “pre-amendment” class III device for which pre-market approval applications (PMAs) have not been required by the FDA. This FDA review process typically takes from four to twelve months, although it can take longer. Most class I devices are exempted from this 510(k) premarket submission requirement. If no legally marketed predicate can be identified for a new device to enable the use of the 510(k) pathway, the device is automatically classified under the FDC Act as class III, which generally requires PMA approval. However, FDA can reclassify or use “de novo classification” for a device that meets the FDC Act standards for a class II device, permitting the device to be marketed without PMA approval. To grant such a reclassification, FDA must determine that the FDC Act’s general controls alone, or general controls and special controls together, are sufficient to provide a reasonable assurance of the device’s safety and effectiveness. The de novo classification route is generally less burdensome than the PMA approval process.
Devices deemed by the FDA to pose the greatest risk, such as life-sustaining, life-supporting, or implantable devices, or those deemed not substantially equivalent to a legally marketed predicate device, are placed in class III. Class III devices typically require PMA approval. To obtain PMA approval, an applicant must demonstrate the reasonable safety and effectiveness of the device based, in part, on data obtained in clinical studies. All clinical studies of investigational medical devices to determine safety and effectiveness must be conducted in accordance with FDA’s investigational device exemption (IDE) regulations, including the requirement for the study sponsor to submit an IDE application to FDA, unless exempt, which must become effective prior to commencing human clinical studies. PMA reviews generally last between one and two years, although they can take longer. Both the 510(k) and the PMA processes can be expensive and lengthy and may not result in clearance or approval. If we are required to submit our products for pre-market review by the FDA, we may be required to delay marketing and commercialization while we obtain premarket clearance or approval from the FDA. There would be no assurance that we could ever obtain such clearance or approval. 
All medical devices, including IVDs, that are regulated by the FDA are also subject to the quality system regulation. Obtaining the requisite regulatory approvals, including the FDA quality system inspections that are required for PMA approval, can be expensive and may involve considerable delay. The regulatory approval process for such products may be significantly delayed, may be significantly more expensive than anticipated, and may conclude without such products being approved by the FDA. Without timely regulatory approval, we will not be able to launch or successfully commercialize such diagnostic products. Changes to the current regulatory framework, including the imposition of additional or new regulations, could arise at any time during the development or marketing of our products. This may negatively affect our ability to obtain or maintain FDA or comparable regulatory clearance or approval of our products in the future. In addition, regulatory agencies may introduce new requirements that may change the regulatory requirements for us or our customers, or both.
As noted above, although our products are currently labeled and sold for research purposes only, the regulatory requirements related to marketing, selling, and supporting such products could be uncertain and depend on the totality of circumstances. This uncertainty exists even if such use by our customers occurs without our consent. If the FDA or other regulatory authorities assert that any of our RUO products are subject to regulatory clearance or approval, our business, financial condition, or results of operations could be adversely affected. 
For example, in some cases, our customers may use our RUO products in their own laboratory-developed tests (LDTs) or in other FDA-regulated products for clinical diagnostic use. The FDA has historically exercised enforcement discretion in not enforcing the medical device regulations against LDTs and LDT manufacturers. However, on October 3, 2014, the FDA issued two draft guidance documents that set forth the FDA’s proposed risk-based framework for regulating LDTs, which are designed, manufactured, and used within a single laboratory. In January 2017, the FDA announced that it would not issue final 
guidance on the oversight of LDTs and LDT manufacturers, but would seek further public discussion on an appropriate oversight approach and give Congress an opportunity to develop a legislative solution. More recently, the FDA has issued warning letters to genomics labs for illegally marketing genetic tests that claim to predict patients’ responses to specific medications, noting that the FDA has not created a legal “carve-out” for LDTs and retains discretion to take action when appropriate, such as when certain genomic tests raise significant public health concerns. As laboratories and manufacturers develop more complex genetic tests and diagnostic software, FDA may increase its regulation of LDTs. Any future legislative or administrative rule making or oversight of LDTs and LDT manufacturers, if and when finalized, may impact the sales of our products and how customers use our products, and may require us to change our business model in order to maintain compliance with these laws. We would become subject to additional FDA requirements if our products are determined to be medical devices or if we elect to seek 510(k) clearance or premarket approval. If our products become subject to FDA regulation as medical devices, we would need to invest significant time and resources to ensure ongoing compliance with FDA quality system regulations and other post-market regulatory requirements. 
International sales of medical devices are subject to foreign government regulations, which vary substantially from country to country. In the future, if we decide to distribute or market our diagnostic products as IVDs in Europe, such products will be subject to regulation under the European Union (EU) IVD Directive and/or the IVD Medical Device Regulation (IVDR) European Union (EU) 2017/746. The IVDR was published in 2017, will replace the IVD Directive, is significantly more extensive than the IVD Directive, including requirements on performance data and quality system, and will become fully enforceable in 2022. Outside of the EU, regulatory approval needs to be sought on a country-by-country basis in order to market medical devices. Although there is a trend towards harmonization of quality system, standards and regulations in each country may vary substantially which can affect timelines of introduction.
As part of the Trump Administration’s efforts to combat COVID-19 and consistent with President Trump’s direction in Executive Orders 13771 (Executive Order on Reducing Regulation and Controlling Regulatory Costs) and 13924 (Executive Order on Regulatory Relief to Support Economic Recovery), the Department of Health and Human Services (HHS) announced rescission of guidance and other informal issuances of the FDA regarding premarket review of LDT absent notice-and-comment rulemaking, stating that, absent notice-and-comment rulemaking, those seeking approval or clearance of, or an emergency use authorization, for an LDT may nonetheless voluntarily submit a premarket approval application, premarket notification or an Emergency Use Authorization request, respectively, but are not required to do so. Although the Biden administration has not taken affirmative steps to rescind this announcement issued by the previous administration, this 2020 HHS policy statement is no longer posted on the HHS website. Further, Congress has recently proposed legislation to create a new LDT and in vitro diagnostic regulatory framework for all in vitro clinical tests that would be separate and distinct from the existing medical device regulatory framework. In June 2021, members of the U.S. House of Representatives formally introduced the VALID Act (Verifying Accurate Leading-edge IVCT Development Act of 2021) and an identical version of the bill was introduced in the U.S. Senate. If passed, the VALID Act would create a new category of medical products separate from medical devices called “in vitro clinical tests,” or IVCTs, and bring all such products within the scope of FDA’s oversight. It is unclear whether the VALID Act or any other legislative proposals would be passed by Congress or signed into law by the President. Any restrictions on LDTs by the FDA, HHS, Congress, or state regulatory authorities may decrease the demand for our products. The adoption of new restrictions on RUOs, whether by the FDA or Congress, could adversely affect demand for our specialized reagents and instruments. 
In the future, to the extent we develop any clinical diagnostic assays, we may pursue payment for such products through a diverse and broad range of channels and seek coverage and reimbursement by government health insurance programs and commercial third-party payors for such products. In the United States, there is no uniform coverage for clinical laboratory tests. The extent of coverage and rate of payment for covered services or items vary from payor to payor. Obtaining coverage and reimbursement for such products can be uncertain, time-consuming, and expensive, and, even if favorable coverage and reimbursement status were attained for our tests, to the extent applicable, less favorable coverage policies and reimbursement rates may be implemented in the future. Changes in healthcare regulatory policies could also increase our costs and subject us to additional regulatory requirements that may interrupt commercialization of our products, decrease our revenue and adversely impact sales of, and pricing of and reimbursement for, our products.
For further discussion of the risks we face relating to regulation, see the section titled “Risk factors— Risks Related to our Business— Risks Related to Regulatory and Legal Compliance Matters.”
The federal Health Insurance Portability and Accountability Act of 1996 (HIPAA), as amended by the Health Information Technology for Economic and Clinical Health Act of 2009 (HITECH), and their implementing regulations, which impose obligations, including mandatory contractual terms, with respect to safeguarding the transmission, security and privacy of protected health information by covered entities subject to HIPAA, such as health plans, health care clearinghouses and healthcare providers, and their respective business associates that access protected health information. HITECH also created new tiers of civil monetary penalties, amended HIPAA to make civil and criminal penalties directly applicable to business 
associates in some cases, and gave state attorneys general new authority to file civil actions for damages or injunctions in federal courts to enforce the federal HIPAA laws and seek attorneys’ fees and costs associated with pursuing federal civil actions.
In addition, in the U.S., numerous federal and state laws and regulations, including state data breach notification laws, state health information privacy laws, and federal and state consumer protection laws, govern the collection, use, disclosure, and protection of health-related and other personal information. For example, in June 2018, the State of California enacted the CCPA, which came into effect on January 1, 2020 and provides new data privacy rights for consumers and new operational requirements for companies. The California Privacy Rights Act (CPRA), whose substantive provisions go into effect in 2023, revises and expands the CCPA. While we are not currently subject to the CCPA, we may in the future be required to comply with the CCPA, which may increase our compliance costs and potential liability. Furthermore, the CCPA could mark the beginning of a trend toward more stringent state privacy legislation in the U.S., which could increase our potential liability and adversely affect our business.
Furthermore, the collection, use, storage, disclosure, transfer, or other processing of personal data regarding individuals in the European Economic Area (EEA), including personal health data, is subject to the GDPR, which became effective on May 25, 2018. The GDPR is wide-ranging in scope and imposes numerous requirements on companies that process personal data, including requirements relating to processing health and other sensitive data, obtaining consent of the individuals to whom the personal data relates, providing information to individuals regarding data processing activities, implementing safeguards to protect the security and confidentiality of personal data, providing notification of data breaches, and taking certain measures when engaging third-party processors. The GDPR also imposes strict rules on the transfer of personal data to countries outside the EEA, including the United States, and permits data protection authorities to impose large penalties for violations of the GDPR, including potential fines of up to €20 million or 4% of annual global revenues, whichever is greater. The GDPR also confers a private right of action on data subjects and consumer associations to lodge complaints with supervisory authorities, seek judicial remedies, and obtain compensation for damages resulting from violations of the GDPR. In addition, the GDPR includes restrictions on cross-border data transfers. The GDPR may increase our responsibility and liability in relation to personal data that we process where such processing is subject to the GDPR, and we may be required to put in place additional mechanisms to ensure compliance with the GDPR, including as implemented by individual countries. Compliance with the GDPR will be a rigorous and time-intensive process that may increase our cost of doing business or require us to change our business practices, and despite those efforts, there is a risk that we may be subject to fines and penalties, litigation, and reputational harm in connection with our European activities. 
Further, with the end of the United Kingdom’s transition period to leave the European Union, or the Brexit transition period, on December 31, 2020, there is uncertainty with regard to medical device and data protection regulations as well as other regulations that may apply to our industry in the United Kingdom, including new guidance, rules, and regulations by the Medicines and Healthcare products Regulatory Agency (MHRA). 
Our research and development processes involve the controlled use of hazardous materials, including select chemicals that may be flammables, toxic or corrosives, which subject us to a variety of federal, state and local environmental and safety laws and regulations. Some of the regulations governing hazardous materials under the current regulatory structure provide for strict liability, holding a party potentially liable without regard to fault or negligence. We could be held liable for damages, remediation costs, and fines as a result of our, or our agents’ or contractors’, business operations should contamination of the environment or individual exposure to hazardous materials occur. We cannot predict how changes in laws or development of new regulations will affect our business operations or the cost of compliance.
For further discussion of the risks we face relating to regulation, see the section titled “Risk factors— Risks Related to our Business— Risks Related to Regulatory and Legal Compliance Matters.”
Intellectual Property
Patents
We strive to obtain and maintain intellectual protection for our products and technology by using a variety of intellectual protection strategies, such as patents, trademarks, trade secrets and other methods of protecting proprietary information. 
As of December 31, 2021, we owned four issued U.S. patents, approximately twenty pending U.S. non-provisional patent applications, approximately fourteen pending U.S. provisional patent applications, and approximately forty-two pending foreign patent applications, including four international patent applications filed under the Patent Cooperation Treaty (PCT application). Our owned patents and patent applications, if issued, are expected to expire between 2037 and 2042, in each case absent any patent term adjustments or extensions and assuming payment of all appropriate maintenance, renewal, annuity, or other governmental fees.
Our solely owned patents and patent applications contain, among others, claims directed to our core platform technology, such as compositions, methods, and systems directed to identifying and quantifying proteins utilizing probes that can bind different epitopes of the proteins with different degrees of binding non-specificity; reagents and materials; instruments; sample preparation; and high throughput decoding algorithms amongst other things. 
Trade Secrets
In addition to patents, we utilize trade secrets and proprietary know-how to boost our competitive position. Specifically, we rely on trade secrets to protect aspects of our business that are not amenable to, or that we do not consider appropriate for, patent protection. We protect trade secrets and know-how by establishing confidentiality agreements and invention assignment agreements with our employees, consultants, scientific advisors, contractors and partners. These agreements generally provide that all confidential information developed or made known during the course of an individual or entity’s relationship with us must be kept confidential during and after the relationship. These agreements also generally provide that all inventions resulting from work performed for us or relating to our business and conceived or completed during the period of employment or assignment, as applicable, shall be our exclusive property. 
Trademarks
As of December 31, 2021, we owned approximately six registered trademarks in China, the United Kingdom, and Europe. In addition, we have three pending trademark applications in the U.S., China and Canada.
Collaboration Agreements
We have entered into research collaboration agreements with Genentech in December 2020, with Amgen in October 2021, and with The University of Texas MD Anderson Cancer Center in October 2021. Under each of these agreements, respective research collaboration teams are using the Nautilus platform to analyze and map proteoforms of interest to the specific collaborator. These agreements are for research only and we will not generate any revenue under the agreements.
Scientific Advisory Board
We have assembled a highly qualified scientific advisory board composed of advisors who have deep expertise in the fields of proteomics, medicine, regulatory compliance and data science. Our scientific advisory board is composed of:
Ruedi Aebersold, Ph.D.
Dr. Aebersold is Professor of Systems Biology at the Institute of Molecular Systems Biology in ETH Zurich (IMSB). He is widely considered a pioneer in the field of proteomics and has served as the head of the biology/disease branch of the human proteome project.
Lee Hartwell, Ph.D.
Dr. Hartwell is the President and Director Emeritus of the Fred Hutchinson Cancer Research Center. He is a 2001 Co-recipient Nobel Prize in Physiology and Medicine for his discovery of the protein molecules that control the division of cells.
Joshua LaBaer, MD, Ph.D.
Dr. LaBaer is the Executive Director of the Biodesign Institute at Arizona State University. He is a leading researcher in cancer and personalized medicine and the inventor of the novel protein microarray technology, Nucleic Acid Programmable Protein Array (NAPPA), which has been used widely for biomedical research.
Emma Lundberg, Ph.D.
Dr. Lundberg is a Professor in cell biology proteomics at KTH Royal Institute of Technology, Sweden, and Director of the Cell Atlas of the Human Protein Atlas, an international proteomics and cell mapping project. Dr. Lundberg also holds the positions of Director of the Cell Profiling facility at the Science for Life Laboratory (SciLifeLab) in Sweden. 
Employees and Human Capital 
As of December 31, 2021, we had 113 employees, all based in the United States, many of whom hold doctorate degrees. Of these employees, 83 were engaged in research and development activities, and 30 were engaged in general and administrative activities. None of our employees are represented by a labor union or covered under a collective bargaining agreement.
Our human capital resources objectives include, as applicable, identifying, recruiting, retaining, incentivizing and integrating our existing and new employees, advisors and consultants. The principal purposes of our equity and cash incentive plans are to attract, retain and reward personnel through the granting of stock-based and cash-based compensation awards, in order to increase stockholder value and the success of our company by motivating such individuals to perform to the best of their abilities and achieve our objectives. 
Corporate and Available Information
Our principal executive offices are located at 2701 Eastlake Avenue East Seattle, Washington, 98102, and our telephone number is (206) 333-2001. Our investor relations website is located at http://www.nautilus.bio/investors/. Information contained on the website is not incorporated by reference into this Form 10-K or any other filings we make with the SEC.
We use our investor relations website to post important information for investors, including news releases, analyst presentations, and supplemental financial information, and as a means of disclosing material non-public information and for complying with our disclosure obligations under Regulation FD. Accordingly, investors should monitor our investor relations website, in addition to following press releases, SEC filings and public conference calls and webcasts. We also make available, free of charge, on our investor relations website under “Financial Information—SEC Filings,” our Annual Reports on Form 10-K, Quarterly Reports on Form 10-Q, Current Reports on Form 8-K and amendments to these reports as soon as reasonably practicable after electronically filing or furnishing those reports to the SEC.
